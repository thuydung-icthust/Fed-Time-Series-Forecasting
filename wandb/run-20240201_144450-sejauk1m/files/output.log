INFO logger 2024-02-01 14:44:58,227 | data_utils.py:383 | Observations info in ElBorn
INFO logger 2024-02-01 14:44:58,227 | data_utils.py:384 | 	Total number of samples:  4192
INFO logger 2024-02-01 14:44:58,228 | data_utils.py:385 | 	Number of samples for training: 3354
INFO logger 2024-02-01 14:44:58,228 | data_utils.py:386 | 	Number of samples for validation:  838
INFO logger 2024-02-01 14:44:58,231 | data_utils.py:383 | Observations info in LesCorts
INFO logger 2024-02-01 14:44:58,231 | data_utils.py:384 | 	Total number of samples:  6892
INFO logger 2024-02-01 14:44:58,232 | data_utils.py:385 | 	Number of samples for training: 5514
INFO logger 2024-02-01 14:44:58,232 | data_utils.py:386 | 	Number of samples for validation:  1378
INFO logger 2024-02-01 14:44:58,236 | data_utils.py:383 | Observations info in PobleSec
INFO logger 2024-02-01 14:44:58,237 | data_utils.py:384 | 	Total number of samples:  15927
INFO logger 2024-02-01 14:44:58,237 | data_utils.py:385 | 	Number of samples for training: 12742
INFO logger 2024-02-01 14:44:58,238 | data_utils.py:386 | 	Number of samples for validation:  3185
INFO logger 2024-02-01 14:44:58,240 | data_utils.py:389 | Observations info using all data
INFO logger 2024-02-01 14:44:58,240 | data_utils.py:390 | 	Total number of samples:  27011
INFO logger 2024-02-01 14:44:58,240 | data_utils.py:391 | 	Number of samples for training: 21610
INFO logger 2024-02-01 14:44:58,241 | data_utils.py:392 | 	Number of samples for validation:  5401
INFO logger 2024-02-01 14:44:58,241 | data_utils.py:118 | Using Flooring and Capping and with params: {'ElBorn': (10, 90), 'LesCorts': (10, 90), 'PobleSec': (5, 95)}
Clients participating training are: dict_keys(['ElBorn', 'LesCorts', 'PobleSec'])
INFO logger 2024-02-01 14:45:00,396 | server.py:71 | Initializing client manager...
INFO logger 2024-02-01 14:45:00,397 | server.py:78 | Registering clients...
INFO logger 2024-02-01 14:45:00,397 | client_manager.py:66 | Registered client with id: ElBorn_0
INFO logger 2024-02-01 14:45:00,397 | client_manager.py:66 | Registered client with id: ElBorn_1
INFO logger 2024-02-01 14:45:00,397 | client_manager.py:66 | Registered client with id: ElBorn_2
INFO logger 2024-02-01 14:45:00,398 | client_manager.py:66 | Registered client with id: ElBorn_3
INFO logger 2024-02-01 14:45:00,398 | client_manager.py:66 | Registered client with id: ElBorn_4
INFO logger 2024-02-01 14:45:00,398 | client_manager.py:66 | Registered client with id: LesCorts_0
INFO logger 2024-02-01 14:45:00,398 | client_manager.py:66 | Registered client with id: LesCorts_1
INFO logger 2024-02-01 14:45:00,398 | client_manager.py:66 | Registered client with id: LesCorts_2
INFO logger 2024-02-01 14:45:00,399 | client_manager.py:66 | Registered client with id: LesCorts_3
INFO logger 2024-02-01 14:45:00,399 | client_manager.py:66 | Registered client with id: LesCorts_4
INFO logger 2024-02-01 14:45:00,399 | client_manager.py:66 | Registered client with id: PobleSec_0
INFO logger 2024-02-01 14:45:00,400 | client_manager.py:66 | Registered client with id: PobleSec_1
INFO logger 2024-02-01 14:45:00,400 | client_manager.py:66 | Registered client with id: PobleSec_2
INFO logger 2024-02-01 14:45:00,400 | client_manager.py:66 | Registered client with id: PobleSec_3
INFO logger 2024-02-01 14:45:00,400 | client_manager.py:66 | Registered client with id: PobleSec_4
INFO logger 2024-02-01 14:45:00,400 | server.py:82 | Client manager initialized!
INFO logger 2024-02-01 14:45:00,401 | server.py:64 | Aggregation algorithm: FedAvg()
INFO logger 2024-02-01 14:45:00,401 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_3']
INFO logger 2024-02-01 14:45:02,098 | server.py:96 | Starting FL rounds
INFO logger 2024-02-01 14:45:02,099 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_1', 'PobleSec_2', 'PobleSec_4', 'ElBorn_0', 'ElBorn_4', 'LesCorts_3', 'LesCorts_2', 'PobleSec_3', 'LesCorts_4', 'ElBorn_2', 'ElBorn_3', 'LesCorts_0', 'PobleSec_0', 'PobleSec_1', 'ElBorn_1']
INFO logger 2024-02-01 14:45:03,482 | train_utils.py:153 | Best Loss: 0.0002896100798708915
INFO logger 2024-02-01 14:45:04,257 | train_utils.py:153 | Best Loss: 0.00048219764949827213
INFO logger 2024-02-01 14:45:05,888 | train_utils.py:153 | Best Loss: 0.0004605070486166111
INFO logger 2024-02-01 14:45:06,561 | train_utils.py:153 | Best Loss: 0.00016069088518115633
INFO logger 2024-02-01 14:45:06,931 | train_utils.py:153 | Best Loss: 2.704441241170887e-05
INFO logger 2024-02-01 14:45:07,491 | train_utils.py:153 | Best Loss: 0.0005478842390908136
INFO logger 2024-02-01 14:45:07,877 | train_utils.py:153 | Best Loss: 0.00021486838037769
[31mStarting poisoning...!
INFO logger 2024-02-01 14:45:08,747 | train_utils.py:153 | Best Loss: 0.00046282758760288006
INFO logger 2024-02-01 14:45:09,645 | train_utils.py:153 | Best Loss: 0.00017418319152461158
INFO logger 2024-02-01 14:45:09,897 | train_utils.py:153 | Best Loss: 2.86163878345925e-05
INFO logger 2024-02-01 14:45:10,134 | train_utils.py:153 | Best Loss: 6.096589588222728e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:45:10,582 | train_utils.py:153 | Best Loss: 0.0007029590864083048
INFO logger 2024-02-01 14:45:11,539 | train_utils.py:153 | Best Loss: 0.000442783231663657
INFO logger 2024-02-01 14:45:12,710 | train_utils.py:153 | Best Loss: 0.0004338021676136753
INFO logger 2024-02-01 14:45:13,302 | train_utils.py:153 | Best Loss: 2.6967046345957523e-05
INFO logger 2024-02-01 14:45:13,345 | server.py:212 | [Global round 1] Aggregating local models...
INFO logger 2024-02-01 14:45:13,346 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['ElBorn_4']
INFO logger 2024-02-01 14:45:13,445 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 3.961508670160412e-05, mse: 0.004847745411098003, rmse: 0.06962575249933033, mae: 0.05451669543981552, nrmse: 0.8616848237779136
INFO logger 2024-02-01 14:45:13,621 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00048044577695605323, mse: 0.06127064302563667, rmse: 0.24752907511166578, mae: 0.11382795870304108, nrmse: 1.3829646121467167
INFO logger 2024-02-01 14:45:13,688 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00045285825767385507, mse: 0.057631950825452805, rmse: 0.240066554991429, mae: 0.18705616891384125, nrmse: 4.097183625781589
INFO logger 2024-02-01 14:45:13,691 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_2', 'PobleSec_2', 'ElBorn_1', 'LesCorts_4', 'ElBorn_4', 'LesCorts_3', 'PobleSec_4', 'PobleSec_0', 'ElBorn_0', 'LesCorts_0', 'LesCorts_1', 'PobleSec_1', 'PobleSec_3', 'LesCorts_2', 'ElBorn_3']
INFO logger 2024-02-01 14:45:14,031 | train_utils.py:153 | Best Loss: 2.302917646770568e-05
INFO logger 2024-02-01 14:45:14,828 | train_utils.py:153 | Best Loss: 0.0004080173598536415
INFO logger 2024-02-01 14:45:15,414 | train_utils.py:153 | Best Loss: 2.1608173087968126e-05
INFO logger 2024-02-01 14:45:15,880 | train_utils.py:153 | Best Loss: 9.99179886237375e-05
INFO logger 2024-02-01 14:45:16,255 | train_utils.py:153 | Best Loss: 2.0147835389274546e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:45:16,751 | train_utils.py:153 | Best Loss: 0.00038533089464606597
INFO logger 2024-02-01 14:45:17,734 | train_utils.py:153 | Best Loss: 0.0003896391208972929
INFO logger 2024-02-01 14:45:18,825 | train_utils.py:153 | Best Loss: 0.00038922138413135696
INFO logger 2024-02-01 14:45:19,464 | train_utils.py:153 | Best Loss: 3.170370318868382e-05
INFO logger 2024-02-01 14:45:20,175 | train_utils.py:153 | Best Loss: 0.00044986266337814385
[31mStarting poisoning...!
INFO logger 2024-02-01 14:45:20,856 | train_utils.py:153 | Best Loss: 0.0001335958759599959
INFO logger 2024-02-01 14:45:22,093 | train_utils.py:153 | Best Loss: 0.00037850218454713193
INFO logger 2024-02-01 14:45:23,488 | train_utils.py:153 | Best Loss: 0.0003945251626116554
INFO logger 2024-02-01 14:45:24,245 | train_utils.py:153 | Best Loss: 9.862699427462199e-05
INFO logger 2024-02-01 14:45:24,800 | train_utils.py:153 | Best Loss: 3.4730777691077925e-05
INFO logger 2024-02-01 14:45:24,865 | server.py:212 | [Global round 2] Aggregating local models...
INFO logger 2024-02-01 14:45:24,867 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_1']
INFO logger 2024-02-01 14:45:24,904 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.660441689571177e-05, mse: 0.0020183438900858164, rmse: 0.0449259823497029, mae: 0.033254317939281464, nrmse: 0.6169358871034012
INFO logger 2024-02-01 14:45:25,006 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00040616167291236205, mse: 0.05178780481219292, rmse: 0.22756934066827395, mae: 0.09434860944747925, nrmse: 1.2714503232309098
INFO logger 2024-02-01 14:45:25,044 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00027694523420282886, mse: 0.03525560349225998, rmse: 0.18776475572444362, mae: 0.14339002966880798, nrmse: 3.0045191111251373
INFO logger 2024-02-01 14:45:25,045 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_0', 'LesCorts_4', 'PobleSec_0', 'ElBorn_3', 'LesCorts_3', 'LesCorts_2', 'PobleSec_3', 'ElBorn_4', 'ElBorn_0', 'PobleSec_2', 'LesCorts_1', 'PobleSec_4', 'ElBorn_2', 'ElBorn_1', 'PobleSec_1']
INFO logger 2024-02-01 14:45:25,434 | train_utils.py:153 | Best Loss: 0.0002295867627083558
[31mStarting poisoning...!
INFO logger 2024-02-01 14:45:25,877 | train_utils.py:153 | Best Loss: 0.00011296577279167305
INFO logger 2024-02-01 14:45:26,831 | train_utils.py:153 | Best Loss: 0.0003654782055312489
INFO logger 2024-02-01 14:45:27,208 | train_utils.py:153 | Best Loss: 2.788655220301471e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:45:27,854 | train_utils.py:153 | Best Loss: 0.0002906876834033177
INFO logger 2024-02-01 14:45:28,386 | train_utils.py:153 | Best Loss: 9.542387452014662e-05
INFO logger 2024-02-01 14:45:29,570 | train_utils.py:153 | Best Loss: 0.0003736173427172416
INFO logger 2024-02-01 14:45:30,140 | train_utils.py:153 | Best Loss: 1.879662109689634e-05
INFO logger 2024-02-01 14:45:30,525 | train_utils.py:153 | Best Loss: 1.0966960507206582e-05
INFO logger 2024-02-01 14:45:31,515 | train_utils.py:153 | Best Loss: 0.0003806010220111824
INFO logger 2024-02-01 14:45:32,124 | train_utils.py:153 | Best Loss: 9.20413162052762e-05
INFO logger 2024-02-01 14:45:33,239 | train_utils.py:153 | Best Loss: 0.0003668655589310907
INFO logger 2024-02-01 14:45:33,730 | train_utils.py:153 | Best Loss: 1.5945831096645643e-05
INFO logger 2024-02-01 14:45:34,057 | train_utils.py:153 | Best Loss: 1.8175303736917567e-05
INFO logger 2024-02-01 14:45:35,358 | train_utils.py:153 | Best Loss: 0.0003617546705925089
INFO logger 2024-02-01 14:45:35,538 | server.py:212 | [Global round 3] Aggregating local models...
INFO logger 2024-02-01 14:45:35,540 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_4']
INFO logger 2024-02-01 14:45:35,682 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.2488633544400226e-05, mse: 0.0015074920374900103, rmse: 0.0388264347769662, mae: 0.02825218439102173, nrmse: 0.5674156109928505
INFO logger 2024-02-01 14:45:35,816 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003747616656212591, mse: 0.047773577272892, rmse: 0.21857167536735403, mae: 0.08759156614542007, nrmse: 1.2254369238766545
INFO logger 2024-02-01 14:45:35,850 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00021762390926001015, mse: 0.027699485421180725, rmse: 0.16643162386151475, mae: 0.12354669719934464, nrmse: 2.3070741520497466
INFO logger 2024-02-01 14:45:35,852 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_2', 'PobleSec_3', 'LesCorts_0', 'ElBorn_3', 'PobleSec_2', 'ElBorn_1', 'PobleSec_1', 'LesCorts_3', 'LesCorts_4', 'LesCorts_1', 'ElBorn_4', 'PobleSec_4', 'ElBorn_0', 'ElBorn_2', 'PobleSec_0']
INFO logger 2024-02-01 14:45:36,290 | train_utils.py:153 | Best Loss: 9.873741727093594e-05
INFO logger 2024-02-01 14:45:37,210 | train_utils.py:153 | Best Loss: 0.000363101266823181
[31mStarting poisoning...!
INFO logger 2024-02-01 14:45:38,048 | train_utils.py:153 | Best Loss: 0.0002271664377890135
INFO logger 2024-02-01 14:45:38,668 | train_utils.py:153 | Best Loss: 2.1113393910382176e-05
INFO logger 2024-02-01 14:45:39,688 | train_utils.py:153 | Best Loss: 0.0003662547502322049
INFO logger 2024-02-01 14:45:40,125 | train_utils.py:153 | Best Loss: 1.4470742465950693e-05
INFO logger 2024-02-01 14:45:40,945 | train_utils.py:153 | Best Loss: 0.00035106648452667977
[31mStarting poisoning...!
INFO logger 2024-02-01 14:45:41,995 | train_utils.py:153 | Best Loss: 0.000259086443383617
INFO logger 2024-02-01 14:45:42,490 | train_utils.py:153 | Best Loss: 0.00010488454758990229
INFO logger 2024-02-01 14:45:42,941 | train_utils.py:153 | Best Loss: 8.854882659564852e-05
INFO logger 2024-02-01 14:45:43,299 | train_utils.py:153 | Best Loss: 1.3500059772606777e-05
INFO logger 2024-02-01 14:45:43,973 | train_utils.py:153 | Best Loss: 0.0003568492590002422
INFO logger 2024-02-01 14:45:44,589 | train_utils.py:153 | Best Loss: 1.0238982318644075e-05
INFO logger 2024-02-01 14:45:44,843 | train_utils.py:153 | Best Loss: 1.3525770405748328e-05
INFO logger 2024-02-01 14:45:45,519 | train_utils.py:153 | Best Loss: 0.00035963782065320674
INFO logger 2024-02-01 14:45:45,659 | server.py:212 | [Global round 4] Aggregating local models...
INFO logger 2024-02-01 14:45:45,661 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_4']
INFO logger 2024-02-01 14:45:45,783 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.2640965594077744e-05, mse: 0.0015237077604979277, rmse: 0.039034699441624084, mae: 0.028191566467285156, nrmse: 0.532600797636718
[31mStarting poisoning...!
INFO logger 2024-02-01 14:45:45,886 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00036090341348963694, mse: 0.045999038964509964, rmse: 0.21447386545803188, mae: 0.0854484885931015, nrmse: 1.2054251778788512
INFO logger 2024-02-01 14:45:45,958 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00019361309255119303, mse: 0.02463039942085743, rmse: 0.15694075130716506, mae: 0.11454938352108002, nrmse: 1.975158623618115
INFO logger 2024-02-01 14:45:45,958 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_3', 'LesCorts_2', 'ElBorn_1', 'ElBorn_4', 'PobleSec_4', 'PobleSec_1', 'PobleSec_2', 'LesCorts_0', 'LesCorts_1', 'LesCorts_4', 'PobleSec_0', 'ElBorn_2', 'PobleSec_3', 'ElBorn_0', 'ElBorn_3']
INFO logger 2024-02-01 14:45:46,736 | train_utils.py:153 | Best Loss: 0.0002438518087984177
INFO logger 2024-02-01 14:45:47,359 | train_utils.py:153 | Best Loss: 9.843106762838294e-05
INFO logger 2024-02-01 14:45:47,664 | train_utils.py:153 | Best Loss: 1.3085417500089692e-05
INFO logger 2024-02-01 14:45:48,051 | train_utils.py:153 | Best Loss: 1.2682861471908608e-05
INFO logger 2024-02-01 14:45:48,798 | train_utils.py:153 | Best Loss: 0.00035147791761376963
INFO logger 2024-02-01 14:45:49,597 | train_utils.py:153 | Best Loss: 0.0003452147070802455
INFO logger 2024-02-01 14:45:50,536 | train_utils.py:153 | Best Loss: 0.0003579691664579757
INFO logger 2024-02-01 14:45:51,137 | train_utils.py:153 | Best Loss: 0.00021082897294770207
INFO logger 2024-02-01 14:45:51,540 | train_utils.py:153 | Best Loss: 8.827174587545601e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:45:51,946 | train_utils.py:153 | Best Loss: 0.00010008457809828265
INFO logger 2024-02-01 14:45:52,746 | train_utils.py:153 | Best Loss: 0.0003528882747545369
INFO logger 2024-02-01 14:45:53,182 | train_utils.py:153 | Best Loss: 1.2632548260156083e-05
INFO logger 2024-02-01 14:45:53,878 | train_utils.py:153 | Best Loss: 0.0003559184255899759
INFO logger 2024-02-01 14:45:54,223 | train_utils.py:153 | Best Loss: 7.28105922040624e-06
INFO logger 2024-02-01 14:45:54,855 | train_utils.py:153 | Best Loss: 1.9471219978137797e-05
INFO logger 2024-02-01 14:45:54,905 | server.py:212 | [Global round 5] Aggregating local models...
INFO logger 2024-02-01 14:45:54,906 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_0']
INFO logger 2024-02-01 14:45:54,990 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.1595696953782172e-05, mse: 0.0013964662794023752, rmse: 0.03736932270462465, mae: 0.02670774981379509, nrmse: 0.5078154382102329
INFO logger 2024-02-01 14:45:55,107 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003521394527949921, mse: 0.044877469539642334, rmse: 0.21184303042498787, mae: 0.08308873325586319, nrmse: 1.1927202423822059
INFO logger 2024-02-01 14:45:55,141 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00017901761944089846, mse: 0.02277003601193428, rmse: 0.15089743540542458, mae: 0.1079343929886818, nrmse: 1.8448199154968805
INFO logger 2024-02-01 14:45:55,146 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_4', 'ElBorn_3', 'ElBorn_4', 'ElBorn_2', 'PobleSec_3', 'PobleSec_1', 'ElBorn_0', 'PobleSec_2', 'PobleSec_0', 'LesCorts_3', 'LesCorts_0', 'ElBorn_1', 'LesCorts_2', 'PobleSec_4', 'LesCorts_1']
INFO logger 2024-02-01 14:45:55,542 | train_utils.py:153 | Best Loss: 9.64155065287885e-05
INFO logger 2024-02-01 14:45:55,812 | train_utils.py:153 | Best Loss: 1.5693589463461065e-05
INFO logger 2024-02-01 14:45:56,086 | train_utils.py:153 | Best Loss: 1.144369713768615e-05
INFO logger 2024-02-01 14:45:56,345 | train_utils.py:153 | Best Loss: 1.1224246101345921e-05
INFO logger 2024-02-01 14:45:57,100 | train_utils.py:153 | Best Loss: 0.00035203374694944833
INFO logger 2024-02-01 14:45:58,359 | train_utils.py:153 | Best Loss: 0.00034122769533854536
INFO logger 2024-02-01 14:45:58,831 | train_utils.py:153 | Best Loss: 7.152758639391314e-06
INFO logger 2024-02-01 14:45:59,706 | train_utils.py:153 | Best Loss: 0.00035290630855120894
INFO logger 2024-02-01 14:46:00,633 | train_utils.py:153 | Best Loss: 0.00034861440020503374
INFO logger 2024-02-01 14:46:01,269 | train_utils.py:153 | Best Loss: 0.00024650548993234046
INFO logger 2024-02-01 14:46:01,747 | train_utils.py:153 | Best Loss: 0.00019618203694665292
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:02,015 | train_utils.py:153 | Best Loss: 1.194723431866814e-05
INFO logger 2024-02-01 14:46:02,358 | train_utils.py:153 | Best Loss: 9.86961340831255e-05
INFO logger 2024-02-01 14:46:03,641 | train_utils.py:153 | Best Loss: 0.0003484128452984132
INFO logger 2024-02-01 14:46:04,096 | train_utils.py:153 | Best Loss: 8.848771689138348e-05
INFO logger 2024-02-01 14:46:04,189 | server.py:212 | [Global round 6] Aggregating local models...
INFO logger 2024-02-01 14:46:04,190 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_4']
INFO logger 2024-02-01 14:46:04,284 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.1073228574677366e-05, mse: 0.0013333798851817846, rmse: 0.03651547459888457, mae: 0.025935936719179153, nrmse: 0.5045855574575326
INFO logger 2024-02-01 14:46:04,409 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003471458257417979, mse: 0.04423769563436508, rmse: 0.2103275912341628, mae: 0.08174784481525421, nrmse: 1.1874939950469101
INFO logger 2024-02-01 14:46:04,445 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00016808946281998303, mse: 0.02137695625424385, rmse: 0.1462086052674187, mae: 0.10313506424427032, nrmse: 1.6884948263073751
INFO logger 2024-02-01 14:46:04,447 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_1', 'PobleSec_3', 'LesCorts_3', 'PobleSec_0', 'LesCorts_1', 'PobleSec_2', 'ElBorn_4', 'ElBorn_3', 'PobleSec_4', 'ElBorn_1', 'LesCorts_4', 'LesCorts_2', 'ElBorn_2', 'LesCorts_0', 'ElBorn_0']
INFO logger 2024-02-01 14:46:05,198 | train_utils.py:153 | Best Loss: 0.0003392768027187567
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:06,105 | train_utils.py:153 | Best Loss: 0.0003489350849821225
INFO logger 2024-02-01 14:46:06,734 | train_utils.py:153 | Best Loss: 0.00023016478180101045
INFO logger 2024-02-01 14:46:07,490 | train_utils.py:153 | Best Loss: 0.00034488046791140487
INFO logger 2024-02-01 14:46:08,166 | train_utils.py:153 | Best Loss: 8.833611163457757e-05
INFO logger 2024-02-01 14:46:08,982 | train_utils.py:153 | Best Loss: 0.00034946928702764155
INFO logger 2024-02-01 14:46:09,406 | train_utils.py:153 | Best Loss: 1.1992304271496472e-05
INFO logger 2024-02-01 14:46:09,754 | train_utils.py:153 | Best Loss: 1.6690122614871118e-05
INFO logger 2024-02-01 14:46:10,644 | train_utils.py:153 | Best Loss: 0.0003468690347293113
INFO logger 2024-02-01 14:46:11,011 | train_utils.py:153 | Best Loss: 1.1368296494379028e-05
INFO logger 2024-02-01 14:46:11,470 | train_utils.py:153 | Best Loss: 9.43371458305863e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:11,935 | train_utils.py:153 | Best Loss: 9.811194906316219e-05
INFO logger 2024-02-01 14:46:12,191 | train_utils.py:153 | Best Loss: 1.0662424000731449e-05
INFO logger 2024-02-01 14:46:12,701 | train_utils.py:153 | Best Loss: 0.00017403584240516376
INFO logger 2024-02-01 14:46:12,996 | train_utils.py:153 | Best Loss: 6.988762807863616e-06
INFO logger 2024-02-01 14:46:13,045 | server.py:212 | [Global round 7] Aggregating local models...
INFO logger 2024-02-01 14:46:13,046 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_2']
INFO logger 2024-02-01 14:46:13,073 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.022446899762566e-05, mse: 0.0012311653699725866, rmse: 0.03508796617036369, mae: 0.024582672864198685, nrmse: 0.4969805484431089
INFO logger 2024-02-01 14:46:13,223 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003438396330952175, mse: 0.043814849108457565, rmse: 0.2093199682506606, mae: 0.08007191121578217, nrmse: 1.18293906367528
INFO logger 2024-02-01 14:46:13,262 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00016281889545273755, mse: 0.02070808783173561, rmse: 0.14390305011269083, mae: 0.10072556883096695, nrmse: 1.6632006197197466
INFO logger 2024-02-01 14:46:13,263 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_0', 'PobleSec_4', 'PobleSec_1', 'LesCorts_0', 'ElBorn_1', 'PobleSec_2', 'PobleSec_3', 'LesCorts_2', 'ElBorn_4', 'LesCorts_4', 'ElBorn_2', 'LesCorts_3', 'ElBorn_0', 'LesCorts_1', 'ElBorn_3']
INFO logger 2024-02-01 14:46:14,147 | train_utils.py:153 | Best Loss: 0.00034257322247323443
INFO logger 2024-02-01 14:46:14,990 | train_utils.py:153 | Best Loss: 0.00034625509920654685
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:15,963 | train_utils.py:153 | Best Loss: 0.0003383340668043224
INFO logger 2024-02-01 14:46:16,538 | train_utils.py:153 | Best Loss: 0.0001762797157361842
INFO logger 2024-02-01 14:46:16,900 | train_utils.py:153 | Best Loss: 1.0813086059963519e-05
INFO logger 2024-02-01 14:46:17,612 | train_utils.py:153 | Best Loss: 0.0003475739399528527
INFO logger 2024-02-01 14:46:18,554 | train_utils.py:153 | Best Loss: 0.0003462874362296535
INFO logger 2024-02-01 14:46:19,034 | train_utils.py:153 | Best Loss: 9.562399739410444e-05
INFO logger 2024-02-01 14:46:19,320 | train_utils.py:153 | Best Loss: 1.1186187148796044e-05
INFO logger 2024-02-01 14:46:19,682 | train_utils.py:153 | Best Loss: 9.283416973268994e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:19,994 | train_utils.py:153 | Best Loss: 1.0201027479072231e-05
INFO logger 2024-02-01 14:46:20,454 | train_utils.py:153 | Best Loss: 0.00020829275963904216
INFO logger 2024-02-01 14:46:20,754 | train_utils.py:153 | Best Loss: 7.246553395640843e-06
INFO logger 2024-02-01 14:46:21,612 | train_utils.py:153 | Best Loss: 8.751571703326415e-05
INFO logger 2024-02-01 14:46:22,135 | train_utils.py:153 | Best Loss: 1.2439932994171078e-05
INFO logger 2024-02-01 14:46:22,204 | server.py:212 | [Global round 8] Aggregating local models...
INFO logger 2024-02-01 14:46:22,205 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['ElBorn_1']
INFO logger 2024-02-01 14:46:22,244 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.954423201607836e-06, mse: 0.001198678044602275, rmse: 0.03462193011087445, mae: 0.024208346381783485, nrmse: 0.48866694099486585
INFO logger 2024-02-01 14:46:22,405 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00034180426295465373, mse: 0.04355398565530777, rmse: 0.20869591671929705, mae: 0.07952078431844711, nrmse: 1.1803596694995666
INFO logger 2024-02-01 14:46:22,458 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015962243690128216, mse: 0.020300906151533127, rmse: 0.14248124842074175, mae: 0.09943710267543793, nrmse: 1.7089029764003867
INFO logger 2024-02-01 14:46:22,459 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_1', 'ElBorn_3', 'LesCorts_0', 'ElBorn_2', 'PobleSec_2', 'LesCorts_1', 'ElBorn_0', 'ElBorn_1', 'LesCorts_4', 'LesCorts_2', 'PobleSec_0', 'LesCorts_3', 'PobleSec_4', 'PobleSec_3', 'ElBorn_4']
INFO logger 2024-02-01 14:46:23,125 | train_utils.py:153 | Best Loss: 0.000338034704730912
INFO logger 2024-02-01 14:46:23,499 | train_utils.py:153 | Best Loss: 1.2067586882602298e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:24,060 | train_utils.py:153 | Best Loss: 0.0001745498153702383
INFO logger 2024-02-01 14:46:24,552 | train_utils.py:153 | Best Loss: 9.87128403255995e-06
INFO logger 2024-02-01 14:46:25,569 | train_utils.py:153 | Best Loss: 0.000346257105125041
INFO logger 2024-02-01 14:46:25,995 | train_utils.py:153 | Best Loss: 8.712375021882748e-05
INFO logger 2024-02-01 14:46:26,252 | train_utils.py:153 | Best Loss: 7.334244642789129e-06
INFO logger 2024-02-01 14:46:26,498 | train_utils.py:153 | Best Loss: 1.0377957151273652e-05
INFO logger 2024-02-01 14:46:26,880 | train_utils.py:153 | Best Loss: 9.259101914307266e-05
INFO logger 2024-02-01 14:46:27,280 | train_utils.py:153 | Best Loss: 9.540632695275528e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:28,275 | train_utils.py:153 | Best Loss: 0.0003410195981108356
INFO logger 2024-02-01 14:46:28,831 | train_utils.py:153 | Best Loss: 0.0002010839838774232
INFO logger 2024-02-01 14:46:29,545 | train_utils.py:153 | Best Loss: 0.00034593604692059943
INFO logger 2024-02-01 14:46:30,731 | train_utils.py:153 | Best Loss: 0.00034534082749829165
INFO logger 2024-02-01 14:46:31,125 | train_utils.py:153 | Best Loss: 1.0607943106397699e-05
INFO logger 2024-02-01 14:46:31,168 | server.py:212 | [Global round 9] Aggregating local models...
INFO logger 2024-02-01 14:46:31,180 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['ElBorn_1']
INFO logger 2024-02-01 14:46:31,267 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.653039539799742e-06, mse: 0.0011623725295066833, rmse: 0.034093584873208675, mae: 0.023848585784435272, nrmse: 0.4836754352804901
INFO logger 2024-02-01 14:46:31,399 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00034072853401156624, mse: 0.043416015803813934, rmse: 0.208365102173598, mae: 0.07901178300380707, nrmse: 1.1803555186710144
INFO logger 2024-02-01 14:46:31,496 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015676234646602288, mse: 0.019937045872211456, rmse: 0.14119860435645762, mae: 0.09865014255046844, nrmse: 1.7058422463556302
INFO logger 2024-02-01 14:46:31,498 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_0', 'ElBorn_3', 'LesCorts_4', 'PobleSec_2', 'ElBorn_1', 'LesCorts_1', 'PobleSec_4', 'LesCorts_0', 'PobleSec_1', 'ElBorn_0', 'LesCorts_2', 'ElBorn_4', 'PobleSec_3', 'ElBorn_2', 'LesCorts_3']
INFO logger 2024-02-01 14:46:32,321 | train_utils.py:153 | Best Loss: 0.0003402420564180636
INFO logger 2024-02-01 14:46:32,983 | train_utils.py:153 | Best Loss: 1.2370722398166387e-05
INFO logger 2024-02-01 14:46:33,753 | train_utils.py:153 | Best Loss: 9.209185849592002e-05
INFO logger 2024-02-01 14:46:34,682 | train_utils.py:153 | Best Loss: 0.0003453289602303833
INFO logger 2024-02-01 14:46:35,021 | train_utils.py:153 | Best Loss: 9.908068462292966e-06
INFO logger 2024-02-01 14:46:35,366 | train_utils.py:153 | Best Loss: 8.647154614313e-05
INFO logger 2024-02-01 14:46:36,432 | train_utils.py:153 | Best Loss: 0.0003459041396258619
INFO logger 2024-02-01 14:46:37,032 | train_utils.py:153 | Best Loss: 0.00015726073084083216
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:38,012 | train_utils.py:153 | Best Loss: 0.0003379967431794471
INFO logger 2024-02-01 14:46:38,621 | train_utils.py:153 | Best Loss: 6.415786699376154e-06
INFO logger 2024-02-01 14:46:39,038 | train_utils.py:153 | Best Loss: 9.576036909333708e-05
INFO logger 2024-02-01 14:46:39,322 | train_utils.py:153 | Best Loss: 1.1000959334809532e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:40,118 | train_utils.py:153 | Best Loss: 0.00034526814712123493
INFO logger 2024-02-01 14:46:40,475 | train_utils.py:153 | Best Loss: 9.585925614672763e-06
INFO logger 2024-02-01 14:46:40,912 | train_utils.py:153 | Best Loss: 0.0001857201160307516
INFO logger 2024-02-01 14:46:40,976 | server.py:212 | [Global round 10] Aggregating local models...
INFO logger 2024-02-01 14:46:40,978 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_2']
INFO logger 2024-02-01 14:46:41,016 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.317049174007154e-06, mse: 0.0011223575565963984, rmse: 0.03350160528387257, mae: 0.02335852012038231, nrmse: 0.4826316420158671
INFO logger 2024-02-01 14:46:41,309 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00034010718642609323, mse: 0.04333585500717163, rmse: 0.20817265672314322, mae: 0.07873134315013885, nrmse: 1.1804352726616878
INFO logger 2024-02-01 14:46:41,344 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.0001540509589038223, mse: 0.019592074677348137, rmse: 0.13997169241438834, mae: 0.09810771048069, nrmse: 1.7582548833110812
INFO logger 2024-02-01 14:46:41,348 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_3', 'PobleSec_1', 'PobleSec_2', 'ElBorn_0', 'PobleSec_0', 'PobleSec_3', 'LesCorts_3', 'LesCorts_1', 'ElBorn_4', 'LesCorts_4', 'ElBorn_2', 'LesCorts_0', 'PobleSec_4', 'LesCorts_2', 'ElBorn_1']
INFO logger 2024-02-01 14:46:41,552 | train_utils.py:153 | Best Loss: 1.2561096317710688e-05
INFO logger 2024-02-01 14:46:42,299 | train_utils.py:153 | Best Loss: 0.0003384218906331074
INFO logger 2024-02-01 14:46:43,164 | train_utils.py:153 | Best Loss: 0.00034528137688840353
INFO logger 2024-02-01 14:46:43,667 | train_utils.py:153 | Best Loss: 6.833501781026523e-06
INFO logger 2024-02-01 14:46:44,519 | train_utils.py:153 | Best Loss: 0.0003401067376496109
INFO logger 2024-02-01 14:46:45,292 | train_utils.py:153 | Best Loss: 0.0003453594182368632
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:46,021 | train_utils.py:153 | Best Loss: 0.00018178266255261256
INFO logger 2024-02-01 14:46:46,462 | train_utils.py:153 | Best Loss: 8.658427940490955e-05
INFO logger 2024-02-01 14:46:46,757 | train_utils.py:153 | Best Loss: 1.1059268015540309e-05
INFO logger 2024-02-01 14:46:47,129 | train_utils.py:153 | Best Loss: 9.211899500955659e-05
INFO logger 2024-02-01 14:46:47,393 | train_utils.py:153 | Best Loss: 9.057856927477363e-06
INFO logger 2024-02-01 14:46:47,861 | train_utils.py:153 | Best Loss: 0.00016064295539774045
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:48,609 | train_utils.py:153 | Best Loss: 0.00034621631882454114
INFO logger 2024-02-01 14:46:49,299 | train_utils.py:153 | Best Loss: 9.455557705627548e-05
INFO logger 2024-02-01 14:46:49,567 | train_utils.py:153 | Best Loss: 1.0237972612564726e-05
INFO logger 2024-02-01 14:46:49,622 | server.py:212 | [Global round 11] Aggregating local models...
INFO logger 2024-02-01 14:46:49,623 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_0']
INFO logger 2024-02-01 14:46:49,697 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.088318936688745e-06, mse: 0.0010946040274575353, rmse: 0.033084800550366555, mae: 0.023072853684425354, nrmse: 0.4875392013404581
INFO logger 2024-02-01 14:46:49,851 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00033991447979892333, mse: 0.04331127181649208, rmse: 0.2081136031510004, mae: 0.07828186452388763, nrmse: 1.1809426889117727
INFO logger 2024-02-01 14:46:49,919 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015286739274984694, mse: 0.019442636519670486, rmse: 0.13943685495474462, mae: 0.09702926874160767, nrmse: 1.7172169835728854
INFO logger 2024-02-01 14:46:49,927 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_1', 'ElBorn_2', 'ElBorn_0', 'LesCorts_3', 'LesCorts_2', 'PobleSec_2', 'ElBorn_1', 'PobleSec_4', 'PobleSec_1', 'PobleSec_3', 'LesCorts_0', 'ElBorn_3', 'ElBorn_4', 'LesCorts_4', 'PobleSec_0']
INFO logger 2024-02-01 14:46:50,260 | train_utils.py:153 | Best Loss: 8.576289169920598e-05
INFO logger 2024-02-01 14:46:50,571 | train_utils.py:153 | Best Loss: 9.085518290549696e-06
INFO logger 2024-02-01 14:46:50,821 | train_utils.py:153 | Best Loss: 6.895280109351762e-06
INFO logger 2024-02-01 14:46:51,349 | train_utils.py:153 | Best Loss: 0.00017173683722857496
INFO logger 2024-02-01 14:46:51,830 | train_utils.py:153 | Best Loss: 9.518737968721847e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:52,701 | train_utils.py:153 | Best Loss: 0.00034501556422576073
INFO logger 2024-02-01 14:46:53,056 | train_utils.py:153 | Best Loss: 9.477917855191561e-06
INFO logger 2024-02-01 14:46:53,801 | train_utils.py:153 | Best Loss: 0.00034659604613456553
INFO logger 2024-02-01 14:46:54,776 | train_utils.py:153 | Best Loss: 0.0003388165087094457
INFO logger 2024-02-01 14:46:55,659 | train_utils.py:153 | Best Loss: 0.00034527464197787246
[31mStarting poisoning...!
INFO logger 2024-02-01 14:46:56,206 | train_utils.py:153 | Best Loss: 0.00017203507966726843
INFO logger 2024-02-01 14:46:56,632 | train_utils.py:153 | Best Loss: 1.0577276034690079e-05
INFO logger 2024-02-01 14:46:56,871 | train_utils.py:153 | Best Loss: 1.0549612351747204e-05
INFO logger 2024-02-01 14:46:57,261 | train_utils.py:153 | Best Loss: 9.083461063391154e-05
INFO logger 2024-02-01 14:46:57,998 | train_utils.py:153 | Best Loss: 0.0003401280264003481
INFO logger 2024-02-01 14:46:58,156 | server.py:212 | [Global round 12] Aggregating local models...
INFO logger 2024-02-01 14:46:58,157 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_2']
INFO logger 2024-02-01 14:46:58,240 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.311264471357896e-06, mse: 0.0011220364831387997, rmse: 0.03349681302958238, mae: 0.02369627356529236, nrmse: 0.497563249824848
INFO logger 2024-02-01 14:46:58,384 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00033996073507124513, mse: 0.04331621527671814, rmse: 0.20812547964321462, mae: 0.07885332405567169, nrmse: 1.1824042265104096
INFO logger 2024-02-01 14:46:58,447 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.0001510609819877849, mse: 0.0192098431289196, rmse: 0.1385995783865146, mae: 0.09719671308994293, nrmse: 1.7901003537564968
INFO logger 2024-02-01 14:46:58,449 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_0', 'PobleSec_2', 'PobleSec_0', 'ElBorn_2', 'PobleSec_1', 'LesCorts_0', 'LesCorts_3', 'ElBorn_4', 'PobleSec_4', 'LesCorts_2', 'ElBorn_3', 'ElBorn_1', 'LesCorts_1', 'LesCorts_4', 'PobleSec_3']
INFO logger 2024-02-01 14:46:58,676 | train_utils.py:153 | Best Loss: 7.353082483697341e-06
INFO logger 2024-02-01 14:46:59,641 | train_utils.py:153 | Best Loss: 0.000345385273933176
INFO logger 2024-02-01 14:47:00,505 | train_utils.py:153 | Best Loss: 0.0003402610209689835
INFO logger 2024-02-01 14:47:00,889 | train_utils.py:153 | Best Loss: 8.800688732847355e-06
INFO logger 2024-02-01 14:47:01,729 | train_utils.py:153 | Best Loss: 0.00033912842829279073
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:02,510 | train_utils.py:153 | Best Loss: 0.00017640669421668638
INFO logger 2024-02-01 14:47:03,389 | train_utils.py:153 | Best Loss: 0.00017134728569167051
INFO logger 2024-02-01 14:47:03,939 | train_utils.py:153 | Best Loss: 1.056174407960568e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:04,765 | train_utils.py:153 | Best Loss: 0.0003469269910247952
INFO logger 2024-02-01 14:47:05,382 | train_utils.py:153 | Best Loss: 9.441891568032099e-05
INFO logger 2024-02-01 14:47:05,741 | train_utils.py:153 | Best Loss: 1.1277084035241013e-05
INFO logger 2024-02-01 14:47:05,995 | train_utils.py:153 | Best Loss: 9.887096621681022e-06
INFO logger 2024-02-01 14:47:06,386 | train_utils.py:153 | Best Loss: 8.577144090685319e-05
INFO logger 2024-02-01 14:47:06,811 | train_utils.py:153 | Best Loss: 9.100806486809201e-05
INFO logger 2024-02-01 14:47:07,560 | train_utils.py:153 | Best Loss: 0.0003455191004772003
INFO logger 2024-02-01 14:47:07,880 | server.py:212 | [Global round 13] Aggregating local models...
INFO logger 2024-02-01 14:47:07,881 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_4']
INFO logger 2024-02-01 14:47:07,973 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.54913436592633e-06, mse: 0.0011514803627505898, rmse: 0.03393346965387698, mae: 0.023819928988814354, nrmse: 0.4843212106277658
INFO logger 2024-02-01 14:47:08,049 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003396452934752534, mse: 0.043276481330394745, rmse: 0.20803000103445354, mae: 0.07855287939310074, nrmse: 1.1819200742691067
INFO logger 2024-02-01 14:47:08,097 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015254401804726812, mse: 0.019399957731366158, rmse: 0.13928373103620595, mae: 0.0965169370174408, nrmse: 1.7418281235814472
INFO logger 2024-02-01 14:47:08,104 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_4', 'PobleSec_3', 'LesCorts_3', 'ElBorn_4', 'PobleSec_0', 'LesCorts_0', 'LesCorts_1', 'PobleSec_1', 'ElBorn_1', 'LesCorts_2', 'ElBorn_0', 'ElBorn_3', 'ElBorn_2', 'PobleSec_4', 'PobleSec_2']
INFO logger 2024-02-01 14:47:08,411 | train_utils.py:153 | Best Loss: 9.2062101956751e-05
INFO logger 2024-02-01 14:47:09,132 | train_utils.py:153 | Best Loss: 0.00034497168344100866
INFO logger 2024-02-01 14:47:09,699 | train_utils.py:153 | Best Loss: 0.00017152855660199944
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:09,986 | train_utils.py:153 | Best Loss: 1.1062339032046352e-05
INFO logger 2024-02-01 14:47:10,879 | train_utils.py:153 | Best Loss: 0.0003404814266511716
INFO logger 2024-02-01 14:47:11,568 | train_utils.py:153 | Best Loss: 0.000166513929851571
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:12,012 | train_utils.py:153 | Best Loss: 8.523774762877552e-05
INFO logger 2024-02-01 14:47:12,810 | train_utils.py:153 | Best Loss: 0.00033897861222347876
INFO logger 2024-02-01 14:47:13,553 | train_utils.py:153 | Best Loss: 9.060780878250762e-06
INFO logger 2024-02-01 14:47:13,924 | train_utils.py:153 | Best Loss: 9.391488056706144e-05
INFO logger 2024-02-01 14:47:14,219 | train_utils.py:153 | Best Loss: 6.668007313127625e-06
INFO logger 2024-02-01 14:47:14,468 | train_utils.py:153 | Best Loss: 1.0730428123455225e-05
INFO logger 2024-02-01 14:47:14,837 | train_utils.py:153 | Best Loss: 8.859484094298548e-06
INFO logger 2024-02-01 14:47:15,624 | train_utils.py:153 | Best Loss: 0.0003471863811366319
INFO logger 2024-02-01 14:47:16,661 | train_utils.py:153 | Best Loss: 0.0003455271041680743
INFO logger 2024-02-01 14:47:16,799 | server.py:212 | [Global round 14] Aggregating local models...
INFO logger 2024-02-01 14:47:16,800 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_1']
INFO logger 2024-02-01 14:47:16,852 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.603607316460947e-06, mse: 0.001157204038463533, rmse: 0.034017701839829405, mae: 0.023638203740119934, nrmse: 0.4836874189872996
INFO logger 2024-02-01 14:47:16,973 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00033945418721959583, mse: 0.04325156658887863, rmse: 0.20797010984484918, mae: 0.07809897512197495, nrmse: 1.1814115671330947
INFO logger 2024-02-01 14:47:17,023 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015237957204430641, mse: 0.019378263503313065, rmse: 0.13920583142711035, mae: 0.09669600427150726, nrmse: 1.7853145520529023
INFO logger 2024-02-01 14:47:17,027 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_0', 'LesCorts_3', 'ElBorn_4', 'ElBorn_2', 'ElBorn_3', 'LesCorts_2', 'LesCorts_0', 'PobleSec_2', 'PobleSec_3', 'PobleSec_1', 'LesCorts_4', 'ElBorn_1', 'LesCorts_1', 'PobleSec_0', 'PobleSec_4']
INFO logger 2024-02-01 14:47:17,245 | train_utils.py:153 | Best Loss: 7.468212456644877e-06
INFO logger 2024-02-01 14:47:17,712 | train_utils.py:153 | Best Loss: 0.00016404519249734126
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:17,989 | train_utils.py:153 | Best Loss: 1.057373738852172e-05
INFO logger 2024-02-01 14:47:18,266 | train_utils.py:153 | Best Loss: 8.746445590094776e-06
INFO logger 2024-02-01 14:47:18,571 | train_utils.py:153 | Best Loss: 1.0964307981286792e-05
INFO logger 2024-02-01 14:47:19,020 | train_utils.py:153 | Best Loss: 9.385707423265218e-05
INFO logger 2024-02-01 14:47:19,581 | train_utils.py:153 | Best Loss: 0.0001645695053215264
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:20,427 | train_utils.py:153 | Best Loss: 0.00034596484196628997
INFO logger 2024-02-01 14:47:21,342 | train_utils.py:153 | Best Loss: 0.00034532848276256576
INFO logger 2024-02-01 14:47:22,375 | train_utils.py:153 | Best Loss: 0.0003396232408566738
INFO logger 2024-02-01 14:47:22,859 | train_utils.py:153 | Best Loss: 9.240648502957795e-05
INFO logger 2024-02-01 14:47:23,148 | train_utils.py:153 | Best Loss: 9.581016838901501e-06
INFO logger 2024-02-01 14:47:23,652 | train_utils.py:153 | Best Loss: 8.521025438046856e-05
INFO logger 2024-02-01 14:47:24,663 | train_utils.py:153 | Best Loss: 0.00034088278337799776
INFO logger 2024-02-01 14:47:25,614 | train_utils.py:153 | Best Loss: 0.0003473219985699677
INFO logger 2024-02-01 14:47:25,766 | server.py:212 | [Global round 15] Aggregating local models...
INFO logger 2024-02-01 14:47:25,768 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_1']
INFO logger 2024-02-01 14:47:25,854 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.55790769452778e-06, mse: 0.0011518150568008423, rmse: 0.03393840091696782, mae: 0.02355935052037239, nrmse: 0.47941963670472
INFO logger 2024-02-01 14:47:25,968 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00033974111384499497, mse: 0.04328810051083565, rmse: 0.20805792585440153, mae: 0.07810176908969879, nrmse: 1.1823752110643297
INFO logger 2024-02-01 14:47:26,003 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015118354791911505, mse: 0.019225148484110832, rmse: 0.13865478168498493, mae: 0.09638284146785736, nrmse: 1.775408104733642
INFO logger 2024-02-01 14:47:26,007 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_1', 'PobleSec_3', 'PobleSec_0', 'ElBorn_1', 'ElBorn_0', 'LesCorts_4', 'ElBorn_3', 'LesCorts_0', 'PobleSec_1', 'PobleSec_4', 'LesCorts_2', 'LesCorts_3', 'ElBorn_4', 'ElBorn_2', 'PobleSec_2']
INFO logger 2024-02-01 14:47:26,324 | train_utils.py:153 | Best Loss: 8.538313232476644e-05
INFO logger 2024-02-01 14:47:27,999 | train_utils.py:153 | Best Loss: 0.0003455492026927903
INFO logger 2024-02-01 14:47:29,905 | train_utils.py:153 | Best Loss: 0.00034097845094117126
INFO logger 2024-02-01 14:47:30,472 | train_utils.py:153 | Best Loss: 9.502223912167592e-06
INFO logger 2024-02-01 14:47:30,784 | train_utils.py:153 | Best Loss: 7.414093954209688e-06
INFO logger 2024-02-01 14:47:31,117 | train_utils.py:153 | Best Loss: 9.205764873029544e-05
INFO logger 2024-02-01 14:47:31,404 | train_utils.py:153 | Best Loss: 1.0691513349572062e-05
INFO logger 2024-02-01 14:47:31,942 | train_utils.py:153 | Best Loss: 0.00016664235841766086
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:32,648 | train_utils.py:153 | Best Loss: 0.00034000202852088634
INFO logger 2024-02-01 14:47:33,617 | train_utils.py:153 | Best Loss: 0.0003477100354773322
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:34,136 | train_utils.py:153 | Best Loss: 9.359400573034079e-05
INFO logger 2024-02-01 14:47:34,652 | train_utils.py:153 | Best Loss: 0.00016857450964114472
INFO logger 2024-02-01 14:47:34,939 | train_utils.py:153 | Best Loss: 1.0763597351291941e-05
INFO logger 2024-02-01 14:47:35,209 | train_utils.py:153 | Best Loss: 8.422131203047499e-06
INFO logger 2024-02-01 14:47:36,221 | train_utils.py:153 | Best Loss: 0.000346234121825546
INFO logger 2024-02-01 14:47:36,375 | server.py:212 | [Global round 16] Aggregating local models...
INFO logger 2024-02-01 14:47:36,377 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_1']
INFO logger 2024-02-01 14:47:36,444 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.336884348351815e-06, mse: 0.0011249862145632505, rmse: 0.033540814160709496, mae: 0.02332202158868313, nrmse: 0.48144152129226125
INFO logger 2024-02-01 14:47:36,583 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00033988148843004244, mse: 0.043305959552526474, rmse: 0.20810083986501945, mae: 0.07789415121078491, nrmse: 1.1830460182114189
INFO logger 2024-02-01 14:47:36,638 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.0001505966901122892, mse: 0.019151095300912857, rmse: 0.1383874824574566, mae: 0.09611549973487854, nrmse: 1.778416519673073
INFO logger 2024-02-01 14:47:36,648 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_3', 'PobleSec_1', 'LesCorts_4', 'LesCorts_1', 'PobleSec_0', 'ElBorn_0', 'ElBorn_2', 'LesCorts_2', 'PobleSec_2', 'LesCorts_3', 'ElBorn_1', 'ElBorn_3', 'LesCorts_0', 'ElBorn_4', 'PobleSec_4']
INFO logger 2024-02-01 14:47:37,323 | train_utils.py:153 | Best Loss: 0.00034581268646233666
INFO logger 2024-02-01 14:47:38,297 | train_utils.py:153 | Best Loss: 0.0003403471779136911
INFO logger 2024-02-01 14:47:38,917 | train_utils.py:153 | Best Loss: 9.182356934509736e-05
INFO logger 2024-02-01 14:47:39,424 | train_utils.py:153 | Best Loss: 8.510395459700049e-05
INFO logger 2024-02-01 14:47:40,136 | train_utils.py:153 | Best Loss: 0.0003412831545162095
INFO logger 2024-02-01 14:47:40,626 | train_utils.py:153 | Best Loss: 7.403394781561469e-06
INFO logger 2024-02-01 14:47:40,964 | train_utils.py:153 | Best Loss: 8.393060975564095e-06
INFO logger 2024-02-01 14:47:41,424 | train_utils.py:153 | Best Loss: 9.285183388560095e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:42,146 | train_utils.py:153 | Best Loss: 0.0003468291993678261
INFO logger 2024-02-01 14:47:42,740 | train_utils.py:153 | Best Loss: 0.00017706582279146066
INFO logger 2024-02-01 14:47:43,068 | train_utils.py:153 | Best Loss: 9.238169427875628e-06
INFO logger 2024-02-01 14:47:43,666 | train_utils.py:153 | Best Loss: 1.0293618995799787e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:44,166 | train_utils.py:153 | Best Loss: 0.00018416335520318202
INFO logger 2024-02-01 14:47:44,482 | train_utils.py:153 | Best Loss: 1.0562084538182739e-05
INFO logger 2024-02-01 14:47:45,306 | train_utils.py:153 | Best Loss: 0.0003479803928474742
INFO logger 2024-02-01 14:47:45,478 | server.py:212 | [Global round 17] Aggregating local models...
INFO logger 2024-02-01 14:47:45,479 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_4']
INFO logger 2024-02-01 14:47:45,627 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.331966082201056e-06, mse: 0.001123822876252234, rmse: 0.0335234675451725, mae: 0.023251745849847794, nrmse: 0.4784757156530739
INFO logger 2024-02-01 14:47:45,803 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00034018751530812716, mse: 0.043345097452402115, rmse: 0.20819485452912162, mae: 0.07781758159399033, nrmse: 1.184004759982925
INFO logger 2024-02-01 14:47:45,838 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015259563632864963, mse: 0.01940733939409256, rmse: 0.1393102271697687, mae: 0.09658455103635788, nrmse: 1.7726731214848677
INFO logger 2024-02-01 14:47:45,843 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_0', 'LesCorts_2', 'LesCorts_0', 'ElBorn_4', 'PobleSec_3', 'PobleSec_4', 'LesCorts_1', 'ElBorn_3', 'PobleSec_1', 'PobleSec_2', 'LesCorts_4', 'ElBorn_1', 'LesCorts_3', 'PobleSec_0', 'ElBorn_2']
INFO logger 2024-02-01 14:47:46,041 | train_utils.py:153 | Best Loss: 7.443172055193119e-06
INFO logger 2024-02-01 14:47:46,665 | train_utils.py:153 | Best Loss: 9.271826091963166e-05
INFO logger 2024-02-01 14:47:47,345 | train_utils.py:153 | Best Loss: 0.00018463932435240662
INFO logger 2024-02-01 14:47:47,622 | train_utils.py:153 | Best Loss: 1.0644095828351768e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:48,383 | train_utils.py:153 | Best Loss: 0.00034592624834379343
INFO logger 2024-02-01 14:47:49,283 | train_utils.py:153 | Best Loss: 0.0003484792647677965
INFO logger 2024-02-01 14:47:49,764 | train_utils.py:153 | Best Loss: 8.48045776195127e-05
INFO logger 2024-02-01 14:47:50,059 | train_utils.py:153 | Best Loss: 1.0529187508489811e-05
INFO logger 2024-02-01 14:47:51,144 | train_utils.py:153 | Best Loss: 0.00034066057257999585
INFO logger 2024-02-01 14:47:52,174 | train_utils.py:153 | Best Loss: 0.0003473077732043003
INFO logger 2024-02-01 14:47:52,656 | train_utils.py:153 | Best Loss: 9.169878948027845e-05
INFO logger 2024-02-01 14:47:52,934 | train_utils.py:153 | Best Loss: 8.902343983788962e-06
INFO logger 2024-02-01 14:47:53,578 | train_utils.py:153 | Best Loss: 0.00017159144334190073
[31mStarting poisoning...!
INFO logger 2024-02-01 14:47:54,480 | train_utils.py:153 | Best Loss: 0.0003415473501241993
INFO logger 2024-02-01 14:47:55,207 | train_utils.py:153 | Best Loss: 8.326946633445e-06
INFO logger 2024-02-01 14:47:55,268 | server.py:212 | [Global round 18] Aggregating local models...
INFO logger 2024-02-01 14:47:55,287 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_0']
INFO logger 2024-02-01 14:47:55,330 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.156076098648282e-06, mse: 0.001102708512917161, rmse: 0.03320705516779771, mae: 0.02303430810570717, nrmse: 0.47705359592100566
INFO logger 2024-02-01 14:47:55,488 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00034049948692087116, mse: 0.04338519647717476, rmse: 0.20829113393799256, mae: 0.07773105055093765, nrmse: 1.184757443011934
INFO logger 2024-02-01 14:47:55,527 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015297995087805024, mse: 0.0194571390748024, rmse: 0.13948884928481703, mae: 0.09639821946620941, nrmse: 1.7863591375683767
INFO logger 2024-02-01 14:47:55,528 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_0', 'ElBorn_3', 'PobleSec_4', 'PobleSec_1', 'PobleSec_2', 'LesCorts_3', 'ElBorn_1', 'PobleSec_3', 'PobleSec_0', 'ElBorn_4', 'LesCorts_4', 'ElBorn_2', 'LesCorts_0', 'LesCorts_1', 'LesCorts_2']
INFO logger 2024-02-01 14:47:55,754 | train_utils.py:153 | Best Loss: 6.6475759672028e-06
INFO logger 2024-02-01 14:47:55,988 | train_utils.py:153 | Best Loss: 9.906689685899855e-06
INFO logger 2024-02-01 14:47:56,962 | train_utils.py:153 | Best Loss: 0.00034890797077201483
INFO logger 2024-02-01 14:47:58,117 | train_utils.py:153 | Best Loss: 0.0003413334917497095
INFO logger 2024-02-01 14:47:59,275 | train_utils.py:153 | Best Loss: 0.0003477264637142185
[31mStarting poisoning...!
INFO logger 2024-02-01 14:48:00,140 | train_utils.py:153 | Best Loss: 0.0001581866043614365
INFO logger 2024-02-01 14:48:00,696 | train_utils.py:153 | Best Loss: 8.671891137143228e-06
INFO logger 2024-02-01 14:48:01,641 | train_utils.py:153 | Best Loss: 0.000346137407111136
INFO logger 2024-02-01 14:48:02,463 | train_utils.py:153 | Best Loss: 0.00034207774542536085
INFO logger 2024-02-01 14:48:02,884 | train_utils.py:153 | Best Loss: 1.0520262896209272e-05
INFO logger 2024-02-01 14:48:03,367 | train_utils.py:153 | Best Loss: 9.1718711137325e-05
INFO logger 2024-02-01 14:48:03,668 | train_utils.py:153 | Best Loss: 8.311643642553349e-06
[31mStarting poisoning...!
INFO logger 2024-02-01 14:48:04,185 | train_utils.py:153 | Best Loss: 0.00016233023414007056
INFO logger 2024-02-01 14:48:04,773 | train_utils.py:153 | Best Loss: 8.481524647104592e-05
INFO logger 2024-02-01 14:48:05,161 | train_utils.py:153 | Best Loss: 9.215966310237714e-05
INFO logger 2024-02-01 14:48:05,270 | server.py:212 | [Global round 19] Aggregating local models...
INFO logger 2024-02-01 14:48:05,280 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_2']
INFO logger 2024-02-01 14:48:05,324 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.121035157077483e-06, mse: 0.0010990677401423454, rmse: 0.03315219057833653, mae: 0.02308729849755764, nrmse: 0.48057313033557003
INFO logger 2024-02-01 14:48:05,467 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003409345550682601, mse: 0.043440431356430054, rmse: 0.20842368233103947, mae: 0.07785725593566895, nrmse: 1.185866360918378
INFO logger 2024-02-01 14:48:05,516 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00014934616710729243, mse: 0.018992070108652115, rmse: 0.13781171977974918, mae: 0.09531854838132858, nrmse: 1.7701737817652676
INFO logger 2024-02-01 14:48:05,518 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_3', 'LesCorts_1', 'PobleSec_0', 'ElBorn_1', 'ElBorn_0', 'ElBorn_4', 'LesCorts_2', 'PobleSec_1', 'PobleSec_4', 'ElBorn_2', 'LesCorts_3', 'LesCorts_0', 'PobleSec_2', 'ElBorn_3', 'LesCorts_4']
INFO logger 2024-02-01 14:48:06,190 | train_utils.py:153 | Best Loss: 0.0003468647897316832
INFO logger 2024-02-01 14:48:07,032 | train_utils.py:153 | Best Loss: 8.494371775679333e-05
INFO logger 2024-02-01 14:48:07,933 | train_utils.py:153 | Best Loss: 0.00034237747161289836
INFO logger 2024-02-01 14:48:08,364 | train_utils.py:153 | Best Loss: 8.954341913649929e-06
INFO logger 2024-02-01 14:48:08,667 | train_utils.py:153 | Best Loss: 7.307354601523007e-06
INFO logger 2024-02-01 14:48:08,994 | train_utils.py:153 | Best Loss: 1.0430406998946435e-05
INFO logger 2024-02-01 14:48:09,365 | train_utils.py:153 | Best Loss: 9.253980746432834e-05
INFO logger 2024-02-01 14:48:10,564 | train_utils.py:153 | Best Loss: 0.00034198125050674506
INFO logger 2024-02-01 14:48:11,668 | train_utils.py:153 | Best Loss: 0.0003494498180592154
[31mStarting poisoning...!
INFO logger 2024-02-01 14:48:12,147 | train_utils.py:153 | Best Loss: 8.198762678649222e-06
INFO logger 2024-02-01 14:48:12,641 | train_utils.py:153 | Best Loss: 0.00015435354138740846
INFO logger 2024-02-01 14:48:13,176 | train_utils.py:153 | Best Loss: 0.00018165996420736375
INFO logger 2024-02-01 14:48:14,039 | train_utils.py:153 | Best Loss: 0.00034822016954421997
[31mStarting poisoning...!
INFO logger 2024-02-01 14:48:14,587 | train_utils.py:153 | Best Loss: 9.381105017663848e-06
INFO logger 2024-02-01 14:48:14,997 | train_utils.py:153 | Best Loss: 9.156419549747343e-05
INFO logger 2024-02-01 14:48:15,097 | server.py:212 | [Global round 20] Aggregating local models...
INFO logger 2024-02-01 14:48:15,098 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_3']
INFO logger 2024-02-01 14:48:15,177 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 9.048658500173566e-06, mse: 0.00108977104537189, rmse: 0.03301168043847344, mae: 0.022854425013065338, nrmse: 0.47651284855302944
INFO logger 2024-02-01 14:48:15,347 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00034117624676955027, mse: 0.043471675366163254, rmse: 0.208498621976653, mae: 0.07750935852527618, nrmse: 1.1867971194373097
INFO logger 2024-02-01 14:48:15,410 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.000151219341205433, mse: 0.019232533872127533, rmse: 0.13868141141525614, mae: 0.09578196704387665, nrmse: 1.7627671384361967
INFO logger 2024-02-01 14:48:15,421 | server.py:133 | Time passed: 193.3216142654419 seconds.
INFO logger 2024-02-01 14:48:15,421 | server.py:134 | Best global model found on fl_round=0 with loss=0.0017594693884394996
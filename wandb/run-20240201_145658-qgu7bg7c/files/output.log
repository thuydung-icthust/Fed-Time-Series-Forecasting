INFO logger 2024-02-01 14:57:03,746 | data_utils.py:383 | Observations info in ElBorn
INFO logger 2024-02-01 14:57:03,746 | data_utils.py:384 | 	Total number of samples:  4192
INFO logger 2024-02-01 14:57:03,746 | data_utils.py:385 | 	Number of samples for training: 3354
INFO logger 2024-02-01 14:57:03,746 | data_utils.py:386 | 	Number of samples for validation:  838
INFO logger 2024-02-01 14:57:03,756 | data_utils.py:383 | Observations info in LesCorts
INFO logger 2024-02-01 14:57:03,756 | data_utils.py:384 | 	Total number of samples:  6892
INFO logger 2024-02-01 14:57:03,756 | data_utils.py:385 | 	Number of samples for training: 5514
INFO logger 2024-02-01 14:57:03,757 | data_utils.py:386 | 	Number of samples for validation:  1378
INFO logger 2024-02-01 14:57:03,760 | data_utils.py:383 | Observations info in PobleSec
INFO logger 2024-02-01 14:57:03,761 | data_utils.py:384 | 	Total number of samples:  15927
INFO logger 2024-02-01 14:57:03,761 | data_utils.py:385 | 	Number of samples for training: 12742
INFO logger 2024-02-01 14:57:03,761 | data_utils.py:386 | 	Number of samples for validation:  3185
INFO logger 2024-02-01 14:57:03,763 | data_utils.py:389 | Observations info using all data
INFO logger 2024-02-01 14:57:03,763 | data_utils.py:390 | 	Total number of samples:  27011
INFO logger 2024-02-01 14:57:03,763 | data_utils.py:391 | 	Number of samples for training: 21610
INFO logger 2024-02-01 14:57:03,763 | data_utils.py:392 | 	Number of samples for validation:  5401
INFO logger 2024-02-01 14:57:03,763 | data_utils.py:118 | Using Flooring and Capping and with params: {'ElBorn': (10, 90), 'LesCorts': (10, 90), 'PobleSec': (5, 95)}
Clients participating training are: dict_keys(['ElBorn', 'LesCorts', 'PobleSec'])
INFO logger 2024-02-01 14:57:05,810 | server.py:71 | Initializing client manager...
INFO logger 2024-02-01 14:57:05,810 | server.py:78 | Registering clients...
INFO logger 2024-02-01 14:57:05,810 | client_manager.py:66 | Registered client with id: ElBorn_0
INFO logger 2024-02-01 14:57:05,810 | client_manager.py:66 | Registered client with id: ElBorn_1
INFO logger 2024-02-01 14:57:05,810 | client_manager.py:66 | Registered client with id: ElBorn_2
INFO logger 2024-02-01 14:57:05,811 | client_manager.py:66 | Registered client with id: ElBorn_3
INFO logger 2024-02-01 14:57:05,811 | client_manager.py:66 | Registered client with id: ElBorn_4
INFO logger 2024-02-01 14:57:05,811 | client_manager.py:66 | Registered client with id: LesCorts_0
INFO logger 2024-02-01 14:57:05,811 | client_manager.py:66 | Registered client with id: LesCorts_1
INFO logger 2024-02-01 14:57:05,811 | client_manager.py:66 | Registered client with id: LesCorts_2
INFO logger 2024-02-01 14:57:05,811 | client_manager.py:66 | Registered client with id: LesCorts_3
INFO logger 2024-02-01 14:57:05,811 | client_manager.py:66 | Registered client with id: LesCorts_4
INFO logger 2024-02-01 14:57:05,811 | client_manager.py:66 | Registered client with id: PobleSec_0
INFO logger 2024-02-01 14:57:05,812 | client_manager.py:66 | Registered client with id: PobleSec_1
INFO logger 2024-02-01 14:57:05,812 | client_manager.py:66 | Registered client with id: PobleSec_2
INFO logger 2024-02-01 14:57:05,812 | client_manager.py:66 | Registered client with id: PobleSec_3
INFO logger 2024-02-01 14:57:05,812 | client_manager.py:66 | Registered client with id: PobleSec_4
INFO logger 2024-02-01 14:57:05,812 | server.py:82 | Client manager initialized!
INFO logger 2024-02-01 14:57:05,812 | server.py:64 | Aggregation algorithm: FedAvg()
INFO logger 2024-02-01 14:57:05,812 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_3']
INFO logger 2024-02-01 14:57:07,842 | server.py:96 | Starting FL rounds
INFO logger 2024-02-01 14:57:07,843 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_1', 'PobleSec_2', 'PobleSec_4', 'ElBorn_0', 'ElBorn_4', 'LesCorts_3', 'LesCorts_2', 'PobleSec_3', 'LesCorts_4', 'ElBorn_2', 'ElBorn_3', 'LesCorts_0', 'PobleSec_0', 'PobleSec_1', 'ElBorn_1']
INFO logger 2024-02-01 14:57:09,166 | train_utils.py:153 | Best Loss: 0.0002896100798708915
INFO logger 2024-02-01 14:57:09,847 | train_utils.py:153 | Best Loss: 0.00048219764949827213
INFO logger 2024-02-01 14:57:11,012 | train_utils.py:153 | Best Loss: 0.0004605070486166111
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:11,500 | train_utils.py:153 | Best Loss: 0.00023076761792895298
INFO logger 2024-02-01 14:57:11,844 | train_utils.py:153 | Best Loss: 2.704441241170887e-05
INFO logger 2024-02-01 14:57:12,264 | train_utils.py:153 | Best Loss: 0.0005479677395121745
INFO logger 2024-02-01 14:57:12,610 | train_utils.py:153 | Best Loss: 0.00021486838037769
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:13,375 | train_utils.py:153 | Best Loss: 0.00046282758760288006
INFO logger 2024-02-01 14:57:13,999 | train_utils.py:153 | Best Loss: 0.00017418319152461158
INFO logger 2024-02-01 14:57:14,355 | train_utils.py:153 | Best Loss: 2.86163878345925e-05
INFO logger 2024-02-01 14:57:14,701 | train_utils.py:153 | Best Loss: 0.00014342772178261895
INFO logger 2024-02-01 14:57:15,233 | train_utils.py:153 | Best Loss: 0.0007241328944021846
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:15,993 | train_utils.py:153 | Best Loss: 0.000442783231663657
INFO logger 2024-02-01 14:57:17,114 | train_utils.py:153 | Best Loss: 0.0004338021676136753
INFO logger 2024-02-01 14:57:17,704 | train_utils.py:153 | Best Loss: 2.6967046345957523e-05
INFO logger 2024-02-01 14:57:17,747 | server.py:212 | [Global round 1] Aggregating local models...
INFO logger 2024-02-01 14:57:17,749 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['ElBorn_4']
INFO logger 2024-02-01 14:57:17,816 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00045863312140804286, mse: 0.058348558843135834, rmse: 0.24155446351317095, mae: 0.18990688025951385, nrmse: 4.097298179651524
INFO logger 2024-02-01 14:57:17,892 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0004801387964623181, mse: 0.061231862753629684, rmse: 0.2474507279310968, mae: 0.11429216712713242, nrmse: 1.3829285177899955
INFO logger 2024-02-01 14:57:17,916 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 4.421744005223691e-05, mse: 0.005398821551352739, rmse: 0.07347667351855784, mae: 0.05757399648427963, nrmse: 0.8791335345106513
INFO logger 2024-02-01 14:57:17,922 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_2', 'PobleSec_2', 'ElBorn_1', 'LesCorts_4', 'ElBorn_4', 'LesCorts_3', 'PobleSec_4', 'PobleSec_0', 'ElBorn_0', 'LesCorts_0', 'LesCorts_1', 'PobleSec_1', 'PobleSec_3', 'LesCorts_2', 'ElBorn_3']
INFO logger 2024-02-01 14:57:18,162 | train_utils.py:153 | Best Loss: 2.3349810837079648e-05
INFO logger 2024-02-01 14:57:19,244 | train_utils.py:153 | Best Loss: 0.0004085212998004176
INFO logger 2024-02-01 14:57:19,978 | train_utils.py:153 | Best Loss: 2.2041385291495185e-05
INFO logger 2024-02-01 14:57:20,440 | train_utils.py:153 | Best Loss: 0.00010000939881946478
INFO logger 2024-02-01 14:57:20,804 | train_utils.py:153 | Best Loss: 2.026585873288377e-05
INFO logger 2024-02-01 14:57:21,220 | train_utils.py:153 | Best Loss: 0.00037832452904716223
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:22,051 | train_utils.py:153 | Best Loss: 0.0003891671022700923
INFO logger 2024-02-01 14:57:23,262 | train_utils.py:153 | Best Loss: 0.0003895595886077233
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:23,893 | train_utils.py:153 | Best Loss: 0.00019234417181839979
INFO logger 2024-02-01 14:57:24,516 | train_utils.py:153 | Best Loss: 0.000453525892736619
INFO logger 2024-02-01 14:57:25,090 | train_utils.py:153 | Best Loss: 0.00013436509462411118
INFO logger 2024-02-01 14:57:26,431 | train_utils.py:153 | Best Loss: 0.00037789111370294115
INFO logger 2024-02-01 14:57:27,850 | train_utils.py:153 | Best Loss: 0.000394974497190904
INFO logger 2024-02-01 14:57:28,373 | train_utils.py:153 | Best Loss: 9.86973324461094e-05
INFO logger 2024-02-01 14:57:28,911 | train_utils.py:153 | Best Loss: 0.00019515344900065574
INFO logger 2024-02-01 14:57:28,955 | server.py:212 | [Global round 2] Aggregating local models...
INFO logger 2024-02-01 14:57:28,957 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_1']
INFO logger 2024-02-01 14:57:29,037 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.0002793284338675657, mse: 0.03553934022784233, rmse: 0.1885188060322957, mae: 0.1450013667345047, nrmse: 2.9747262116315074
INFO logger 2024-02-01 14:57:29,113 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00040611547953265856, mse: 0.05178189277648926, rmse: 0.22755635077160394, mae: 0.09460113197565079, nrmse: 1.2721984217659106
INFO logger 2024-02-01 14:57:29,138 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 2.04608297922563e-05, mse: 0.002481213305145502, rmse: 0.049811778779175336, mae: 0.036261361092329025, nrmse: 0.6138446772944136
INFO logger 2024-02-01 14:57:29,143 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_0', 'LesCorts_4', 'PobleSec_0', 'ElBorn_3', 'LesCorts_3', 'LesCorts_2', 'PobleSec_3', 'ElBorn_4', 'ElBorn_0', 'PobleSec_2', 'LesCorts_1', 'PobleSec_4', 'ElBorn_2', 'ElBorn_1', 'PobleSec_1']
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:29,547 | train_utils.py:153 | Best Loss: 0.00025993420426564956
INFO logger 2024-02-01 14:57:30,123 | train_utils.py:153 | Best Loss: 0.00011000158067803546
INFO logger 2024-02-01 14:57:31,176 | train_utils.py:153 | Best Loss: 0.000367205083318876
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:31,745 | train_utils.py:153 | Best Loss: 0.00016298960525416522
INFO logger 2024-02-01 14:57:32,262 | train_utils.py:153 | Best Loss: 0.0002882295105693459
INFO logger 2024-02-01 14:57:32,742 | train_utils.py:153 | Best Loss: 9.519176313256006e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:33,642 | train_utils.py:153 | Best Loss: 0.00037384906501369917
INFO logger 2024-02-01 14:57:33,994 | train_utils.py:153 | Best Loss: 1.7492648367072648e-05
INFO logger 2024-02-01 14:57:34,375 | train_utils.py:153 | Best Loss: 0.00014205607878053247
INFO logger 2024-02-01 14:57:35,278 | train_utils.py:153 | Best Loss: 0.0003808275399010951
INFO logger 2024-02-01 14:57:35,848 | train_utils.py:153 | Best Loss: 9.252824745691049e-05
INFO logger 2024-02-01 14:57:36,861 | train_utils.py:153 | Best Loss: 0.0003667511288663299
INFO logger 2024-02-01 14:57:37,274 | train_utils.py:153 | Best Loss: 1.6406897774893017e-05
INFO logger 2024-02-01 14:57:37,594 | train_utils.py:153 | Best Loss: 1.8130719199425716e-05
INFO logger 2024-02-01 14:57:38,403 | train_utils.py:153 | Best Loss: 0.00036053463112650894
INFO logger 2024-02-01 14:57:38,667 | server.py:212 | [Global round 3] Aggregating local models...
INFO logger 2024-02-01 14:57:38,668 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_4']
INFO logger 2024-02-01 14:57:38,779 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00022413821724837112, mse: 0.028519099578261375, rmse: 0.16887598875583637, mae: 0.1267978847026825, nrmse: 2.3599884539503493
INFO logger 2024-02-01 14:57:38,920 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00037432767117146664, mse: 0.04771758243441582, rmse: 0.21844354518826098, mae: 0.08781707286834717, nrmse: 1.2266049583718417
INFO logger 2024-02-01 14:57:38,973 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.5338045260351566e-05, mse: 0.0018509298097342253, rmse: 0.043022433796035126, mae: 0.030664756894111633, nrmse: 0.5680959369943548
INFO logger 2024-02-01 14:57:38,974 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_2', 'PobleSec_3', 'LesCorts_0', 'ElBorn_3', 'PobleSec_2', 'ElBorn_1', 'PobleSec_1', 'LesCorts_3', 'LesCorts_4', 'LesCorts_1', 'ElBorn_4', 'PobleSec_4', 'ElBorn_0', 'ElBorn_2', 'PobleSec_0']
INFO logger 2024-02-01 14:57:39,327 | train_utils.py:153 | Best Loss: 9.657100131680743e-05
INFO logger 2024-02-01 14:57:40,081 | train_utils.py:153 | Best Loss: 0.00036227303439765934
INFO logger 2024-02-01 14:57:40,972 | train_utils.py:153 | Best Loss: 0.00019190280306103982
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:41,412 | train_utils.py:153 | Best Loss: 0.00011450519947254139
INFO logger 2024-02-01 14:57:42,652 | train_utils.py:153 | Best Loss: 0.00036606083398567525
INFO logger 2024-02-01 14:57:42,978 | train_utils.py:153 | Best Loss: 1.458716952772856e-05
INFO logger 2024-02-01 14:57:43,837 | train_utils.py:153 | Best Loss: 0.0003507599312313429
INFO logger 2024-02-01 14:57:45,071 | train_utils.py:153 | Best Loss: 0.00023872173957700967
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:45,525 | train_utils.py:153 | Best Loss: 0.00010309094489601098
INFO logger 2024-02-01 14:57:45,993 | train_utils.py:153 | Best Loss: 8.863350512645049e-05
INFO logger 2024-02-01 14:57:46,310 | train_utils.py:153 | Best Loss: 1.2524458602214781e-05
INFO logger 2024-02-01 14:57:47,269 | train_utils.py:153 | Best Loss: 0.00035625223576377226
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:48,028 | train_utils.py:153 | Best Loss: 0.00014080558588575338
INFO logger 2024-02-01 14:57:48,384 | train_utils.py:153 | Best Loss: 1.3748992708003248e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:49,468 | train_utils.py:153 | Best Loss: 0.00035893665087651313
INFO logger 2024-02-01 14:57:49,649 | server.py:212 | [Global round 4] Aggregating local models...
INFO logger 2024-02-01 14:57:49,650 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_4']
INFO logger 2024-02-01 14:57:49,781 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00019619788576941393, mse: 0.02494790591299534, rmse: 0.15794906113363047, mae: 0.11594289541244507, nrmse: 2.0104382147519866
INFO logger 2024-02-01 14:57:49,906 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003608713202603807, mse: 0.045994602143764496, rmse: 0.21446352170885494, mae: 0.0858321487903595, nrmse: 1.2051237730127515
INFO logger 2024-02-01 14:57:49,929 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.5215323686797695e-05, mse: 0.001832854701206088, rmse: 0.042811852344953355, mae: 0.030538642778992653, nrmse: 0.5374482739959325
INFO logger 2024-02-01 14:57:49,934 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_3', 'LesCorts_2', 'ElBorn_1', 'ElBorn_4', 'PobleSec_4', 'PobleSec_1', 'PobleSec_2', 'LesCorts_0', 'LesCorts_1', 'LesCorts_4', 'PobleSec_0', 'ElBorn_2', 'PobleSec_3', 'ElBorn_0', 'ElBorn_3']
INFO logger 2024-02-01 14:57:50,308 | train_utils.py:153 | Best Loss: 0.00022658213226898024
INFO logger 2024-02-01 14:57:50,953 | train_utils.py:153 | Best Loss: 9.792023617501932e-05
INFO logger 2024-02-01 14:57:51,373 | train_utils.py:153 | Best Loss: 1.3004734792751102e-05
INFO logger 2024-02-01 14:57:51,616 | train_utils.py:153 | Best Loss: 1.1615690793212197e-05
INFO logger 2024-02-01 14:57:52,485 | train_utils.py:153 | Best Loss: 0.0003511058124456936
INFO logger 2024-02-01 14:57:53,649 | train_utils.py:153 | Best Loss: 0.000344277759867273
INFO logger 2024-02-01 14:57:56,447 | train_utils.py:153 | Best Loss: 0.00035759256890512944
INFO logger 2024-02-01 14:57:57,190 | train_utils.py:153 | Best Loss: 0.0002228515345211092
[31mStarting poisoning...!
INFO logger 2024-02-01 14:57:57,554 | train_utils.py:153 | Best Loss: 8.856323026855917e-05
INFO logger 2024-02-01 14:57:57,910 | train_utils.py:153 | Best Loss: 9.914991454008901e-05
INFO logger 2024-02-01 14:57:58,795 | train_utils.py:153 | Best Loss: 0.0003520876170121368
INFO logger 2024-02-01 14:57:59,397 | train_utils.py:153 | Best Loss: 1.303400565388698e-05
INFO logger 2024-02-01 14:58:00,148 | train_utils.py:153 | Best Loss: 0.0003559000469289544
INFO logger 2024-02-01 14:58:00,612 | train_utils.py:153 | Best Loss: 0.00016269463807308442
INFO logger 2024-02-01 14:58:01,073 | train_utils.py:153 | Best Loss: 0.00011658274730586487
INFO logger 2024-02-01 14:58:01,117 | server.py:212 | [Global round 5] Aggregating local models...
INFO logger 2024-02-01 14:58:01,118 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_0']
INFO logger 2024-02-01 14:58:01,192 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00018279997588336816, mse: 0.02323790267109871, rmse: 0.15243983295418134, mae: 0.11000518500804901, nrmse: 1.8250199730175507
INFO logger 2024-02-01 14:58:01,268 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003522836426492986, mse: 0.04489509016275406, rmse: 0.21188461521015173, mae: 0.08375097811222076, nrmse: 1.1929276762640928
INFO logger 2024-02-01 14:58:01,291 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.4881778745754546e-05, mse: 0.0017907287692651153, rmse: 0.04231700331149543, mae: 0.029758062213659286, nrmse: 0.5171011432127244
INFO logger 2024-02-01 14:58:01,296 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_4', 'ElBorn_3', 'ElBorn_4', 'ElBorn_2', 'PobleSec_3', 'PobleSec_1', 'ElBorn_0', 'PobleSec_2', 'PobleSec_0', 'LesCorts_3', 'LesCorts_0', 'ElBorn_1', 'LesCorts_2', 'PobleSec_4', 'LesCorts_1']
[31mStarting poisoning...!
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:01,587 | train_utils.py:153 | Best Loss: 9.614576473941057e-05
INFO logger 2024-02-01 14:58:01,977 | train_utils.py:153 | Best Loss: 0.00013053542956853836
INFO logger 2024-02-01 14:58:02,331 | train_utils.py:153 | Best Loss: 1.1586652833019081e-05
INFO logger 2024-02-01 14:58:02,817 | train_utils.py:153 | Best Loss: 1.1834438205786626e-05
INFO logger 2024-02-01 14:58:04,143 | train_utils.py:153 | Best Loss: 0.0003519935965332694
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:05,484 | train_utils.py:153 | Best Loss: 0.00034076324889553694
INFO logger 2024-02-01 14:58:05,953 | train_utils.py:153 | Best Loss: 0.00016037980881902043
INFO logger 2024-02-01 14:58:06,843 | train_utils.py:153 | Best Loss: 0.00035233032524835053
INFO logger 2024-02-01 14:58:08,315 | train_utils.py:153 | Best Loss: 0.00034872955952470347
INFO logger 2024-02-01 14:58:09,054 | train_utils.py:153 | Best Loss: 0.00021183793841485392
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:09,552 | train_utils.py:153 | Best Loss: 0.00018375466594047714
INFO logger 2024-02-01 14:58:09,809 | train_utils.py:153 | Best Loss: 1.2222798594615562e-05
INFO logger 2024-02-01 14:58:10,179 | train_utils.py:153 | Best Loss: 9.795108487372075e-05
INFO logger 2024-02-01 14:58:11,254 | train_utils.py:153 | Best Loss: 0.00034789201017014504
INFO logger 2024-02-01 14:58:11,912 | train_utils.py:153 | Best Loss: 8.881967756434273e-05
INFO logger 2024-02-01 14:58:12,000 | server.py:212 | [Global round 6] Aggregating local models...
INFO logger 2024-02-01 14:58:12,001 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_4']
INFO logger 2024-02-01 14:58:12,066 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00017160265835829906, mse: 0.02181161940097809, rmse: 0.14768757361734294, mae: 0.10493950545787811, nrmse: 1.6872527262106456
INFO logger 2024-02-01 14:58:12,139 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003472777236047692, mse: 0.04425401985645294, rmse: 0.21036639431347617, mae: 0.08233191072940826, nrmse: 1.1867001166158664
INFO logger 2024-02-01 14:58:12,188 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.3932310424943046e-05, mse: 0.0016766421031206846, rmse: 0.04094682042748478, mae: 0.02871878445148468, nrmse: 0.514604233253449
INFO logger 2024-02-01 14:58:12,189 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_1', 'PobleSec_3', 'LesCorts_3', 'PobleSec_0', 'LesCorts_1', 'PobleSec_2', 'ElBorn_4', 'ElBorn_3', 'PobleSec_4', 'ElBorn_1', 'LesCorts_4', 'LesCorts_2', 'ElBorn_2', 'LesCorts_0', 'ElBorn_0']
INFO logger 2024-02-01 14:58:13,167 | train_utils.py:153 | Best Loss: 0.0003388810649836861
INFO logger 2024-02-01 14:58:14,085 | train_utils.py:153 | Best Loss: 0.00034929978521907424
INFO logger 2024-02-01 14:58:14,889 | train_utils.py:153 | Best Loss: 0.00021341661595853796
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:16,129 | train_utils.py:153 | Best Loss: 0.0003443248291301915
INFO logger 2024-02-01 14:58:16,723 | train_utils.py:153 | Best Loss: 8.858842737782115e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:17,493 | train_utils.py:153 | Best Loss: 0.00034914532533340803
INFO logger 2024-02-01 14:58:17,821 | train_utils.py:153 | Best Loss: 1.1527611424692047e-05
INFO logger 2024-02-01 14:58:18,304 | train_utils.py:153 | Best Loss: 0.00012641922224331016
INFO logger 2024-02-01 14:58:19,351 | train_utils.py:153 | Best Loss: 0.00034633095557691425
INFO logger 2024-02-01 14:58:19,706 | train_utils.py:153 | Best Loss: 1.149161687572959e-05
INFO logger 2024-02-01 14:58:20,255 | train_utils.py:153 | Best Loss: 9.43439833585674e-05
INFO logger 2024-02-01 14:58:20,644 | train_utils.py:153 | Best Loss: 9.782431539616477e-05
INFO logger 2024-02-01 14:58:20,992 | train_utils.py:153 | Best Loss: 1.1078259389699046e-05
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:21,593 | train_utils.py:153 | Best Loss: 0.0001779913028146614
INFO logger 2024-02-01 14:58:21,966 | train_utils.py:153 | Best Loss: 0.00015876979616601111
INFO logger 2024-02-01 14:58:22,009 | server.py:212 | [Global round 7] Aggregating local models...
INFO logger 2024-02-01 14:58:22,012 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_2']
INFO logger 2024-02-01 14:58:22,069 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00016821491837022248, mse: 0.02137722820043564, rmse: 0.14620953525825747, mae: 0.10300350189208984, nrmse: 1.5829287873122806
INFO logger 2024-02-01 14:58:22,502 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003454837535588643, mse: 0.04402399808168411, rmse: 0.20981896501909478, mae: 0.08211949467658997, nrmse: 1.1830650643304108
INFO logger 2024-02-01 14:58:22,561 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.461817804220074e-05, mse: 0.0017569486517459154, rmse: 0.04191597132055889, mae: 0.029448112472891808, nrmse: 0.5038572957288129
INFO logger 2024-02-01 14:58:22,562 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_0', 'PobleSec_4', 'PobleSec_1', 'LesCorts_0', 'ElBorn_1', 'PobleSec_2', 'PobleSec_3', 'LesCorts_2', 'ElBorn_4', 'LesCorts_4', 'ElBorn_2', 'LesCorts_3', 'ElBorn_0', 'LesCorts_1', 'ElBorn_3']
INFO logger 2024-02-01 14:58:23,359 | train_utils.py:153 | Best Loss: 0.00034237226111975713
INFO logger 2024-02-01 14:58:24,213 | train_utils.py:153 | Best Loss: 0.0003456628843811964
INFO logger 2024-02-01 14:58:25,339 | train_utils.py:153 | Best Loss: 0.000338023588955989
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:26,002 | train_utils.py:153 | Best Loss: 0.00018979706229609356
INFO logger 2024-02-01 14:58:26,327 | train_utils.py:153 | Best Loss: 1.0902567087236234e-05
INFO logger 2024-02-01 14:58:27,395 | train_utils.py:153 | Best Loss: 0.00034743678006233543
INFO logger 2024-02-01 14:58:28,486 | train_utils.py:153 | Best Loss: 0.0003477631067292486
INFO logger 2024-02-01 14:58:29,260 | train_utils.py:153 | Best Loss: 9.58784816280138e-05
INFO logger 2024-02-01 14:58:29,564 | train_utils.py:153 | Best Loss: 1.162884199872595e-05
INFO logger 2024-02-01 14:58:30,051 | train_utils.py:153 | Best Loss: 9.376217566201823e-05
INFO logger 2024-02-01 14:58:30,452 | train_utils.py:153 | Best Loss: 1.1116843195384647e-05
INFO logger 2024-02-01 14:58:31,023 | train_utils.py:153 | Best Loss: 0.00021596650908869958
[31mStarting poisoning...!
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:31,530 | train_utils.py:153 | Best Loss: 0.0001537827111258743
INFO logger 2024-02-01 14:58:31,981 | train_utils.py:153 | Best Loss: 8.757215412605924e-05
INFO logger 2024-02-01 14:58:32,296 | train_utils.py:153 | Best Loss: 0.00010069485546814071
INFO logger 2024-02-01 14:58:32,341 | server.py:212 | [Global round 8] Aggregating local models...
INFO logger 2024-02-01 14:58:32,343 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['ElBorn_1']
INFO logger 2024-02-01 14:58:32,379 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.0001649105256254518, mse: 0.020961182191967964, rmse: 0.14477977134934275, mae: 0.10192229598760605, nrmse: 1.5556728191971139
INFO logger 2024-02-01 14:58:32,454 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00034348992755504573, mse: 0.043769143521785736, rmse: 0.2092107633985062, mae: 0.08081690967082977, nrmse: 1.180744129971383
INFO logger 2024-02-01 14:58:32,477 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.3685646885331126e-05, mse: 0.0016453780699521303, rmse: 0.040563260100146416, mae: 0.028242792934179306, nrmse: 0.504026033980518
INFO logger 2024-02-01 14:58:32,482 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_1', 'ElBorn_3', 'LesCorts_0', 'ElBorn_2', 'PobleSec_2', 'LesCorts_1', 'ElBorn_0', 'ElBorn_1', 'LesCorts_4', 'LesCorts_2', 'PobleSec_0', 'LesCorts_3', 'PobleSec_4', 'PobleSec_3', 'ElBorn_4']
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:33,459 | train_utils.py:153 | Best Loss: 0.0003377789977431943
INFO logger 2024-02-01 14:58:34,120 | train_utils.py:153 | Best Loss: 9.957452108948559e-05
INFO logger 2024-02-01 14:58:34,764 | train_utils.py:153 | Best Loss: 0.00018793849917183146
INFO logger 2024-02-01 14:58:35,108 | train_utils.py:153 | Best Loss: 1.0891130476951563e-05
INFO logger 2024-02-01 14:58:35,912 | train_utils.py:153 | Best Loss: 0.0003462607589894979
INFO logger 2024-02-01 14:58:36,498 | train_utils.py:153 | Best Loss: 8.675296758900653e-05
INFO logger 2024-02-01 14:58:36,849 | train_utils.py:153 | Best Loss: 0.00013252879731393092
INFO logger 2024-02-01 14:58:37,138 | train_utils.py:153 | Best Loss: 1.0472501190559228e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:37,680 | train_utils.py:153 | Best Loss: 9.308139996450634e-05
INFO logger 2024-02-01 14:58:38,220 | train_utils.py:153 | Best Loss: 9.545391563010233e-05
INFO logger 2024-02-01 14:58:38,987 | train_utils.py:153 | Best Loss: 0.00034144283470323705
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:39,689 | train_utils.py:153 | Best Loss: 0.0002095936511626892
INFO logger 2024-02-01 14:58:40,672 | train_utils.py:153 | Best Loss: 0.00034555205488650815
INFO logger 2024-02-01 14:58:41,659 | train_utils.py:153 | Best Loss: 0.00034642160992966745
INFO logger 2024-02-01 14:58:42,051 | train_utils.py:153 | Best Loss: 1.112139407840022e-05
INFO logger 2024-02-01 14:58:42,094 | server.py:212 | [Global round 9] Aggregating local models...
INFO logger 2024-02-01 14:58:42,095 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['ElBorn_1']
INFO logger 2024-02-01 14:58:42,191 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.0001612811201941004, mse: 0.020498434081673622, rmse: 0.1431727421043322, mae: 0.10111446678638458, nrmse: 1.6221676839934127
INFO logger 2024-02-01 14:58:42,325 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003421073206003726, mse: 0.043591417372226715, rmse: 0.20878557750052257, mae: 0.0803895816206932, nrmse: 1.1797740422084768
INFO logger 2024-02-01 14:58:42,350 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.3289383892644791e-05, mse: 0.001598056172952056, rmse: 0.03997569477760275, mae: 0.02771841362118721, nrmse: 0.493285049981932
INFO logger 2024-02-01 14:58:42,350 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_0', 'ElBorn_3', 'LesCorts_4', 'PobleSec_2', 'ElBorn_1', 'LesCorts_1', 'PobleSec_4', 'LesCorts_0', 'PobleSec_1', 'ElBorn_0', 'LesCorts_2', 'ElBorn_4', 'PobleSec_3', 'ElBorn_2', 'LesCorts_3']
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:43,572 | train_utils.py:153 | Best Loss: 0.00034076411053391657
INFO logger 2024-02-01 14:58:44,127 | train_utils.py:153 | Best Loss: 0.00010166136021523371
INFO logger 2024-02-01 14:58:44,758 | train_utils.py:153 | Best Loss: 9.275205148797896e-05
INFO logger 2024-02-01 14:58:45,655 | train_utils.py:153 | Best Loss: 0.00034578235572438657
INFO logger 2024-02-01 14:58:46,210 | train_utils.py:153 | Best Loss: 1.0460207423258231e-05
INFO logger 2024-02-01 14:58:46,641 | train_utils.py:153 | Best Loss: 8.651438681136447e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:47,824 | train_utils.py:153 | Best Loss: 0.0003456254831082591
INFO logger 2024-02-01 14:58:48,583 | train_utils.py:153 | Best Loss: 0.00016983849955014667
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:49,795 | train_utils.py:153 | Best Loss: 0.00033776958049531645
INFO logger 2024-02-01 14:58:50,418 | train_utils.py:153 | Best Loss: 0.0001570003023955989
INFO logger 2024-02-01 14:58:50,822 | train_utils.py:153 | Best Loss: 9.529124683297473e-05
INFO logger 2024-02-01 14:58:51,118 | train_utils.py:153 | Best Loss: 1.1602531784497526e-05
INFO logger 2024-02-01 14:58:52,017 | train_utils.py:153 | Best Loss: 0.000346452061409556
INFO logger 2024-02-01 14:58:52,670 | train_utils.py:153 | Best Loss: 1.0523862843199268e-05
INFO logger 2024-02-01 14:58:53,171 | train_utils.py:153 | Best Loss: 0.0001827601318884837
INFO logger 2024-02-01 14:58:53,241 | server.py:212 | [Global round 10] Aggregating local models...
INFO logger 2024-02-01 14:58:53,242 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_2']
INFO logger 2024-02-01 14:58:53,340 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00016002216694974586, mse: 0.020337725058197975, rmse: 0.1426103960382902, mae: 0.1006409078836441, nrmse: 1.6483836869179727
INFO logger 2024-02-01 14:58:53,469 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003409080916106349, mse: 0.043438006192445755, rmse: 0.2084178643793419, mae: 0.0794609785079956, nrmse: 1.177842842502437
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:53,493 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.2800313283774803e-05, mse: 0.0015373026253655553, rmse: 0.03920845094320299, mae: 0.027566319331526756, nrmse: 0.5080264771964746
INFO logger 2024-02-01 14:58:53,498 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_3', 'PobleSec_1', 'PobleSec_2', 'ElBorn_0', 'PobleSec_0', 'PobleSec_3', 'LesCorts_3', 'LesCorts_1', 'ElBorn_4', 'LesCorts_4', 'ElBorn_2', 'LesCorts_0', 'PobleSec_4', 'LesCorts_2', 'ElBorn_1']
INFO logger 2024-02-01 14:58:54,011 | train_utils.py:153 | Best Loss: 8.829692288657318e-05
INFO logger 2024-02-01 14:58:55,317 | train_utils.py:153 | Best Loss: 0.00033795957213385015
INFO logger 2024-02-01 14:58:56,723 | train_utils.py:153 | Best Loss: 0.0003457870329803545
INFO logger 2024-02-01 14:58:57,281 | train_utils.py:153 | Best Loss: 0.00015284932456946604
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:58,222 | train_utils.py:153 | Best Loss: 0.00033953580895336124
INFO logger 2024-02-01 14:58:59,252 | train_utils.py:153 | Best Loss: 0.0003459117296481813
[31mStarting poisoning...!
INFO logger 2024-02-01 14:58:59,865 | train_utils.py:153 | Best Loss: 0.000187871317319267
INFO logger 2024-02-01 14:59:00,317 | train_utils.py:153 | Best Loss: 8.596101628033695e-05
INFO logger 2024-02-01 14:59:00,587 | train_utils.py:153 | Best Loss: 1.1073702742156668e-05
INFO logger 2024-02-01 14:59:01,003 | train_utils.py:153 | Best Loss: 9.212370370296837e-05
INFO logger 2024-02-01 14:59:01,274 | train_utils.py:153 | Best Loss: 1.0206754817649867e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:01,724 | train_utils.py:153 | Best Loss: 0.0001634897511692075
INFO logger 2024-02-01 14:59:02,768 | train_utils.py:153 | Best Loss: 0.0003461315857033854
INFO logger 2024-02-01 14:59:03,486 | train_utils.py:153 | Best Loss: 9.527357127680851e-05
INFO logger 2024-02-01 14:59:03,849 | train_utils.py:153 | Best Loss: 1.0179953353259047e-05
INFO logger 2024-02-01 14:59:03,927 | server.py:212 | [Global round 11] Aggregating local models...
INFO logger 2024-02-01 14:59:03,928 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_0']
INFO logger 2024-02-01 14:59:03,997 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015739455740158145, mse: 0.020004063844680786, rmse: 0.14143572336818158, mae: 0.09880608320236206, nrmse: 1.5517574410819097
INFO logger 2024-02-01 14:59:04,113 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003410356824366948, mse: 0.04345392435789108, rmse: 0.20845604898369124, mae: 0.07958334684371948, nrmse: 1.1792661408650087
INFO logger 2024-02-01 14:59:04,156 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.2755656619398779e-05, mse: 0.0015340253012254834, rmse: 0.039166635051092705, mae: 0.027262592688202858, nrmse: 0.5019407039369164
INFO logger 2024-02-01 14:59:04,159 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_1', 'ElBorn_2', 'ElBorn_0', 'LesCorts_3', 'LesCorts_2', 'PobleSec_2', 'ElBorn_1', 'PobleSec_4', 'PobleSec_1', 'PobleSec_3', 'LesCorts_0', 'ElBorn_3', 'ElBorn_4', 'LesCorts_4', 'PobleSec_0']
INFO logger 2024-02-01 14:59:04,557 | train_utils.py:153 | Best Loss: 8.580600740714816e-05
INFO logger 2024-02-01 14:59:04,838 | train_utils.py:153 | Best Loss: 9.996769767016136e-06
INFO logger 2024-02-01 14:59:05,138 | train_utils.py:153 | Best Loss: 0.000144115824630295
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:05,555 | train_utils.py:153 | Best Loss: 0.00019578451878930392
INFO logger 2024-02-01 14:59:06,154 | train_utils.py:153 | Best Loss: 9.46671594402682e-05
INFO logger 2024-02-01 14:59:06,870 | train_utils.py:153 | Best Loss: 0.0003459690004315843
INFO logger 2024-02-01 14:59:07,239 | train_utils.py:153 | Best Loss: 9.782129228295047e-06
INFO logger 2024-02-01 14:59:08,093 | train_utils.py:153 | Best Loss: 0.0003461509075485111
INFO logger 2024-02-01 14:59:08,862 | train_utils.py:153 | Best Loss: 0.00033835851935684445
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:09,813 | train_utils.py:153 | Best Loss: 0.00034627414946481
INFO logger 2024-02-01 14:59:10,362 | train_utils.py:153 | Best Loss: 0.00015603884515401565
INFO logger 2024-02-01 14:59:10,676 | train_utils.py:153 | Best Loss: 0.00010155169135814416
INFO logger 2024-02-01 14:59:10,942 | train_utils.py:153 | Best Loss: 1.074105966836214e-05
INFO logger 2024-02-01 14:59:11,275 | train_utils.py:153 | Best Loss: 9.189194973084356e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:12,113 | train_utils.py:153 | Best Loss: 0.0003405651179193629
INFO logger 2024-02-01 14:59:12,265 | server.py:212 | [Global round 12] Aggregating local models...
INFO logger 2024-02-01 14:59:12,266 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_2']
INFO logger 2024-02-01 14:59:12,451 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.0001616361831813201, mse: 0.02054593898355961, rmse: 0.14333854674706176, mae: 0.10007403045892715, nrmse: 1.619089197575799
INFO logger 2024-02-01 14:59:12,577 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00034053644561392115, mse: 0.04339032247662544, rmse: 0.20830343846568025, mae: 0.07920565456151962, nrmse: 1.1780158686969062
INFO logger 2024-02-01 14:59:12,608 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.3187562243716009e-05, mse: 0.0015853103250265121, rmse: 0.03981595565883748, mae: 0.027729516848921776, nrmse: 0.5040294518505489
INFO logger 2024-02-01 14:59:12,612 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_0', 'PobleSec_2', 'PobleSec_0', 'ElBorn_2', 'PobleSec_1', 'LesCorts_0', 'LesCorts_3', 'ElBorn_4', 'PobleSec_4', 'LesCorts_2', 'ElBorn_3', 'ElBorn_1', 'LesCorts_1', 'LesCorts_4', 'PobleSec_3']
INFO logger 2024-02-01 14:59:12,981 | train_utils.py:153 | Best Loss: 0.00015723427807111384
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:13,768 | train_utils.py:153 | Best Loss: 0.0003461304259867825
INFO logger 2024-02-01 14:59:14,894 | train_utils.py:153 | Best Loss: 0.00034095608379955834
INFO logger 2024-02-01 14:59:15,536 | train_utils.py:153 | Best Loss: 9.688738832511187e-06
INFO logger 2024-02-01 14:59:17,502 | train_utils.py:153 | Best Loss: 0.0003382413961198621
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:18,347 | train_utils.py:153 | Best Loss: 0.00018698323180365285
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:18,927 | train_utils.py:153 | Best Loss: 0.00018807079463282176
INFO logger 2024-02-01 14:59:19,338 | train_utils.py:153 | Best Loss: 9.999455052319968e-06
INFO logger 2024-02-01 14:59:20,103 | train_utils.py:153 | Best Loss: 0.00034600621529334174
INFO logger 2024-02-01 14:59:20,798 | train_utils.py:153 | Best Loss: 9.253661353168301e-05
INFO logger 2024-02-01 14:59:21,252 | train_utils.py:153 | Best Loss: 9.677427087501051e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:21,536 | train_utils.py:153 | Best Loss: 9.694642692147462e-06
INFO logger 2024-02-01 14:59:21,873 | train_utils.py:153 | Best Loss: 8.46744966026047e-05
INFO logger 2024-02-01 14:59:22,232 | train_utils.py:153 | Best Loss: 9.216310586426299e-05
INFO logger 2024-02-01 14:59:23,445 | train_utils.py:153 | Best Loss: 0.0003458181676990169
INFO logger 2024-02-01 14:59:23,579 | server.py:212 | [Global round 13] Aggregating local models...
INFO logger 2024-02-01 14:59:23,580 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_4']
INFO logger 2024-02-01 14:59:23,651 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015883087891981832, mse: 0.020188724622130394, rmse: 0.14208703185769767, mae: 0.09998854249715805, nrmse: 1.692079268268336
INFO logger 2024-02-01 14:59:23,772 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00034034384509885874, mse: 0.04336480051279068, rmse: 0.2082421679506595, mae: 0.07896549254655838, nrmse: 1.1789574018147118
INFO logger 2024-02-01 14:59:23,804 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.2902896975027622e-05, mse: 0.001551518333144486, rmse: 0.039389317500364056, mae: 0.02684738114476204, nrmse: 0.4773159667744506
INFO logger 2024-02-01 14:59:23,806 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_4', 'PobleSec_3', 'LesCorts_3', 'ElBorn_4', 'PobleSec_0', 'LesCorts_0', 'LesCorts_1', 'PobleSec_1', 'ElBorn_1', 'LesCorts_2', 'ElBorn_0', 'ElBorn_3', 'ElBorn_2', 'PobleSec_4', 'PobleSec_2']
INFO logger 2024-02-01 14:59:24,179 | train_utils.py:153 | Best Loss: 9.284464779244572e-05
INFO logger 2024-02-01 14:59:25,191 | train_utils.py:153 | Best Loss: 0.00034644008859786694
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:26,109 | train_utils.py:153 | Best Loss: 0.00017937576283880494
INFO logger 2024-02-01 14:59:26,446 | train_utils.py:153 | Best Loss: 1.058777204291796e-05
INFO logger 2024-02-01 14:59:27,421 | train_utils.py:153 | Best Loss: 0.00034143421058286364
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:28,068 | train_utils.py:153 | Best Loss: 0.00016163161694349949
INFO logger 2024-02-01 14:59:28,564 | train_utils.py:153 | Best Loss: 8.507517941857072e-05
INFO logger 2024-02-01 14:59:29,606 | train_utils.py:153 | Best Loss: 0.0003387121068621714
INFO logger 2024-02-01 14:59:29,929 | train_utils.py:153 | Best Loss: 9.854542651632126e-06
INFO logger 2024-02-01 14:59:30,302 | train_utils.py:153 | Best Loss: 9.319495272888034e-05
INFO logger 2024-02-01 14:59:30,740 | train_utils.py:153 | Best Loss: 0.00018148798639503654
INFO logger 2024-02-01 14:59:31,058 | train_utils.py:153 | Best Loss: 0.00011634218938432741
INFO logger 2024-02-01 14:59:31,297 | train_utils.py:153 | Best Loss: 9.50997930969413e-06
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:32,186 | train_utils.py:153 | Best Loss: 0.00034691286724295437
INFO logger 2024-02-01 14:59:32,998 | train_utils.py:153 | Best Loss: 0.0003466643721202579
INFO logger 2024-02-01 14:59:33,167 | server.py:212 | [Global round 14] Aggregating local models...
INFO logger 2024-02-01 14:59:33,168 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_1']
INFO logger 2024-02-01 14:59:33,310 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015694725688693948, mse: 0.019948655739426613, rmse: 0.14123971020724524, mae: 0.10032596439123154, nrmse: 1.7956186971242891
INFO logger 2024-02-01 14:59:33,385 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00033997867667064893, mse: 0.04331784322857857, rmse: 0.20812939059291594, mae: 0.07899215072393417, nrmse: 1.1805013673213554
INFO logger 2024-02-01 14:59:33,409 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.238418228706066e-05, mse: 0.0014902569819241762, rmse: 0.038603846724441546, mae: 0.02671380713582039, nrmse: 0.4874964188913243
INFO logger 2024-02-01 14:59:33,411 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_0', 'LesCorts_3', 'ElBorn_4', 'ElBorn_2', 'ElBorn_3', 'LesCorts_2', 'LesCorts_0', 'PobleSec_2', 'PobleSec_3', 'PobleSec_1', 'LesCorts_4', 'ElBorn_1', 'LesCorts_1', 'PobleSec_0', 'PobleSec_4']
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:33,757 | train_utils.py:153 | Best Loss: 0.00012351227204364856
INFO logger 2024-02-01 14:59:34,253 | train_utils.py:153 | Best Loss: 0.0001671251538618092
INFO logger 2024-02-01 14:59:34,619 | train_utils.py:153 | Best Loss: 1.0061609375421048e-05
INFO logger 2024-02-01 14:59:34,934 | train_utils.py:153 | Best Loss: 9.346791812452682e-06
INFO logger 2024-02-01 14:59:35,461 | train_utils.py:153 | Best Loss: 0.00011228750558830977
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:35,806 | train_utils.py:153 | Best Loss: 9.413969625408451e-05
INFO logger 2024-02-01 14:59:36,496 | train_utils.py:153 | Best Loss: 0.00018774893418041586
INFO logger 2024-02-01 14:59:37,601 | train_utils.py:153 | Best Loss: 0.00034680477818327507
INFO logger 2024-02-01 14:59:38,618 | train_utils.py:153 | Best Loss: 0.00034646554314714717
INFO logger 2024-02-01 14:59:40,160 | train_utils.py:153 | Best Loss: 0.0003391896748885982
INFO logger 2024-02-01 14:59:41,642 | train_utils.py:153 | Best Loss: 9.356619251009665e-05
INFO logger 2024-02-01 14:59:42,059 | train_utils.py:153 | Best Loss: 9.739453452166872e-06
INFO logger 2024-02-01 14:59:42,421 | train_utils.py:153 | Best Loss: 8.492223215180487e-05
INFO logger 2024-02-01 14:59:43,206 | train_utils.py:153 | Best Loss: 0.00034152505560008093
INFO logger 2024-02-01 14:59:44,277 | train_utils.py:153 | Best Loss: 0.00034738215163174105
INFO logger 2024-02-01 14:59:44,424 | server.py:212 | [Global round 15] Aggregating local models...
INFO logger 2024-02-01 14:59:44,425 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_1']
INFO logger 2024-02-01 14:59:44,524 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015534602387465144, mse: 0.019743233919143677, rmse: 0.1405106185280802, mae: 0.09938226640224457, nrmse: 1.8138743826670343
INFO logger 2024-02-01 14:59:44,637 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003402617434039712, mse: 0.0433541014790535, rmse: 0.20821647744367758, mae: 0.07888205349445343, nrmse: 1.181358370556731
INFO logger 2024-02-01 14:59:44,667 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.2501631005766132e-05, mse: 0.0015044031897559762, rmse: 0.03878663674200144, mae: 0.026886070147156715, nrmse: 0.48967551247165886
INFO logger 2024-02-01 14:59:44,668 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_1', 'PobleSec_3', 'PobleSec_0', 'ElBorn_1', 'ElBorn_0', 'LesCorts_4', 'ElBorn_3', 'LesCorts_0', 'PobleSec_1', 'PobleSec_4', 'LesCorts_2', 'LesCorts_3', 'ElBorn_4', 'ElBorn_2', 'PobleSec_2']
INFO logger 2024-02-01 14:59:45,076 | train_utils.py:153 | Best Loss: 8.467286968146239e-05
INFO logger 2024-02-01 14:59:45,739 | train_utils.py:153 | Best Loss: 0.000346183693183102
INFO logger 2024-02-01 14:59:46,712 | train_utils.py:153 | Best Loss: 0.0003420683231358746
INFO logger 2024-02-01 14:59:47,164 | train_utils.py:153 | Best Loss: 9.653874130802598e-06
INFO logger 2024-02-01 14:59:47,548 | train_utils.py:153 | Best Loss: 0.00017694612416092325
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:47,944 | train_utils.py:153 | Best Loss: 9.336955052234058e-05
INFO logger 2024-02-01 14:59:48,498 | train_utils.py:153 | Best Loss: 0.00011169800876779256
INFO logger 2024-02-01 14:59:49,013 | train_utils.py:153 | Best Loss: 0.00017222250016591355
INFO logger 2024-02-01 14:59:49,992 | train_utils.py:153 | Best Loss: 0.0003397811032230342
INFO logger 2024-02-01 14:59:50,835 | train_utils.py:153 | Best Loss: 0.0003474561707299995
INFO logger 2024-02-01 14:59:51,430 | train_utils.py:153 | Best Loss: 9.360656496927099e-05
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:51,868 | train_utils.py:153 | Best Loss: 0.00016559701826837327
INFO logger 2024-02-01 14:59:52,129 | train_utils.py:153 | Best Loss: 1.0084307691811219e-05
INFO logger 2024-02-01 14:59:52,483 | train_utils.py:153 | Best Loss: 9.090216801690774e-06
INFO logger 2024-02-01 14:59:53,361 | train_utils.py:153 | Best Loss: 0.0003473187750022066
INFO logger 2024-02-01 14:59:53,573 | server.py:212 | [Global round 16] Aggregating local models...
INFO logger 2024-02-01 14:59:53,574 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_1']
INFO logger 2024-02-01 14:59:53,670 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015434691064980164, mse: 0.019617373123764992, rmse: 0.14006203312734322, mae: 0.0991126298904419, nrmse: 1.827131218154924
INFO logger 2024-02-01 14:59:53,778 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003403553130897129, mse: 0.04336585849523544, rmse: 0.20824470820463947, mae: 0.07871155440807343, nrmse: 1.1825209666797634
INFO logger 2024-02-01 14:59:53,807 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.2134425938219409e-05, mse: 0.0014599182177335024, rmse: 0.03820887616423051, mae: 0.026517551392316818, nrmse: 0.48959682702278706
INFO logger 2024-02-01 14:59:53,808 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_3', 'PobleSec_1', 'LesCorts_4', 'LesCorts_1', 'PobleSec_0', 'ElBorn_0', 'ElBorn_2', 'LesCorts_2', 'PobleSec_2', 'LesCorts_3', 'ElBorn_1', 'ElBorn_3', 'LesCorts_0', 'ElBorn_4', 'PobleSec_4']
INFO logger 2024-02-01 14:59:54,749 | train_utils.py:153 | Best Loss: 0.000346535848101645
INFO logger 2024-02-01 14:59:55,533 | train_utils.py:153 | Best Loss: 0.0003401183322306693
INFO logger 2024-02-01 14:59:55,987 | train_utils.py:153 | Best Loss: 9.315855677201473e-05
INFO logger 2024-02-01 14:59:56,344 | train_utils.py:153 | Best Loss: 8.463781879811782e-05
INFO logger 2024-02-01 14:59:57,393 | train_utils.py:153 | Best Loss: 0.00034188207132580475
[31mStarting poisoning...!
INFO logger 2024-02-01 14:59:57,879 | train_utils.py:153 | Best Loss: 0.00011222727218831795
INFO logger 2024-02-01 14:59:58,218 | train_utils.py:153 | Best Loss: 8.98302296527486e-06
INFO logger 2024-02-01 14:59:58,682 | train_utils.py:153 | Best Loss: 9.31473531588716e-05
INFO logger 2024-02-01 14:59:59,472 | train_utils.py:153 | Best Loss: 0.0003474841201604586
[31mStarting poisoning...!
INFO logger 2024-02-01 15:00:00,306 | train_utils.py:153 | Best Loss: 0.00018595018674624943
INFO logger 2024-02-01 15:00:00,582 | train_utils.py:153 | Best Loss: 9.590303913379708e-06
INFO logger 2024-02-01 15:00:00,877 | train_utils.py:153 | Best Loss: 9.291111446629112e-05
INFO logger 2024-02-01 15:00:01,454 | train_utils.py:153 | Best Loss: 0.00018564119461204922
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 15:00:01,862 | train_utils.py:153 | Best Loss: 9.901261259126814e-06
INFO logger 2024-02-01 15:00:02,743 | train_utils.py:153 | Best Loss: 0.00034763433743180254
INFO logger 2024-02-01 15:00:02,897 | server.py:212 | [Global round 17] Aggregating local models...
INFO logger 2024-02-01 15:00:02,898 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_4']
INFO logger 2024-02-01 15:00:03,061 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015431227862333868, mse: 0.019612137228250504, rmse: 0.14004334053517326, mae: 0.10011114925146103, nrmse: 1.9267784473860716
INFO logger 2024-02-01 15:00:03,194 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003407585194818382, mse: 0.04341735318303108, rmse: 0.20836831136963002, mae: 0.07895057648420334, nrmse: 1.183689056110061
INFO logger 2024-02-01 15:00:03,236 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.2417681780103864e-05, mse: 0.0014940743567422032, rmse: 0.03865325803528343, mae: 0.026651645079255104, nrmse: 0.4754205387123098
INFO logger 2024-02-01 15:00:03,248 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_0', 'LesCorts_2', 'LesCorts_0', 'ElBorn_4', 'PobleSec_3', 'PobleSec_4', 'LesCorts_1', 'ElBorn_3', 'PobleSec_1', 'PobleSec_2', 'LesCorts_4', 'ElBorn_1', 'LesCorts_3', 'PobleSec_0', 'ElBorn_2']
INFO logger 2024-02-01 15:00:03,504 | train_utils.py:153 | Best Loss: 0.0001499074171544705
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 15:00:04,204 | train_utils.py:153 | Best Loss: 9.310619336449438e-05
INFO logger 2024-02-01 15:00:04,652 | train_utils.py:153 | Best Loss: 0.0001695001734780115
INFO logger 2024-02-01 15:00:04,920 | train_utils.py:153 | Best Loss: 9.838072765857018e-06
INFO logger 2024-02-01 15:00:05,782 | train_utils.py:153 | Best Loss: 0.0003463877849720829
INFO logger 2024-02-01 15:00:06,910 | train_utils.py:153 | Best Loss: 0.00034825786269878544
INFO logger 2024-02-01 15:00:07,515 | train_utils.py:153 | Best Loss: 8.44895940107887e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 15:00:08,015 | train_utils.py:153 | Best Loss: 8.318517728290264e-05
INFO logger 2024-02-01 15:00:08,873 | train_utils.py:153 | Best Loss: 0.00034084975363789347
INFO logger 2024-02-01 15:00:10,230 | train_utils.py:153 | Best Loss: 0.0003478357892512806
INFO logger 2024-02-01 15:00:11,311 | train_utils.py:153 | Best Loss: 9.360064208447628e-05
[31mStarting poisoning...!
INFO logger 2024-02-01 15:00:11,752 | train_utils.py:153 | Best Loss: 9.638523406817033e-06
INFO logger 2024-02-01 15:00:12,329 | train_utils.py:153 | Best Loss: 0.0001742368678382614
INFO logger 2024-02-01 15:00:13,220 | train_utils.py:153 | Best Loss: 0.00034222629339265544
INFO logger 2024-02-01 15:00:13,620 | train_utils.py:153 | Best Loss: 8.820210584070408e-06
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 15:00:13,663 | server.py:212 | [Global round 18] Aggregating local models...
INFO logger 2024-02-01 15:00:13,665 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_0']
INFO logger 2024-02-01 15:00:13,717 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015289148663671698, mse: 0.01943141408264637, rmse: 0.13939660714180374, mae: 0.09909281879663467, nrmse: 1.8793809922843387
INFO logger 2024-02-01 15:00:13,805 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00034090404413405833, mse: 0.043436199426651, rmse: 0.20841352985507203, mae: 0.07856647670269012, nrmse: 1.1845156811544197
INFO logger 2024-02-01 15:00:13,836 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.2125360657424994e-05, mse: 0.0014589146012440324, rmse: 0.0381957406165142, mae: 0.026503700762987137, nrmse: 0.48446061090984216
INFO logger 2024-02-01 15:00:13,841 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['ElBorn_0', 'ElBorn_3', 'PobleSec_4', 'PobleSec_1', 'PobleSec_2', 'LesCorts_3', 'ElBorn_1', 'PobleSec_3', 'PobleSec_0', 'ElBorn_4', 'LesCorts_4', 'ElBorn_2', 'LesCorts_0', 'LesCorts_1', 'LesCorts_2']
INFO logger 2024-02-01 15:00:14,095 | train_utils.py:153 | Best Loss: 0.00014772926961130277
INFO logger 2024-02-01 15:00:14,558 | train_utils.py:153 | Best Loss: 8.436376993782855e-05
INFO logger 2024-02-01 15:00:15,589 | train_utils.py:153 | Best Loss: 0.0003482212338552583
INFO logger 2024-02-01 15:00:16,744 | train_utils.py:153 | Best Loss: 0.0003413607399566026
[31mStarting poisoning...!
INFO logger 2024-02-01 15:00:17,831 | train_utils.py:153 | Best Loss: 0.00034804472754760754
INFO logger 2024-02-01 15:00:18,478 | train_utils.py:153 | Best Loss: 0.0001678595017118935
INFO logger 2024-02-01 15:00:19,126 | train_utils.py:153 | Best Loss: 9.254775483021737e-06
INFO logger 2024-02-01 15:00:19,832 | train_utils.py:153 | Best Loss: 0.0003466676592122851
INFO logger 2024-02-01 15:00:20,833 | train_utils.py:153 | Best Loss: 0.00034243923391941497
INFO logger 2024-02-01 15:00:21,417 | train_utils.py:153 | Best Loss: 9.446369232677355e-06
[31mStarting poisoning...!
INFO logger 2024-02-01 15:00:21,830 | train_utils.py:153 | Best Loss: 9.314255153743975e-05
INFO logger 2024-02-01 15:00:22,088 | train_utils.py:153 | Best Loss: 8.67875071314438e-06
INFO logger 2024-02-01 15:00:22,556 | train_utils.py:153 | Best Loss: 0.00017566639488857043
INFO logger 2024-02-01 15:00:22,945 | train_utils.py:153 | Best Loss: 8.402467580724573e-05
INFO logger 2024-02-01 15:00:23,398 | train_utils.py:153 | Best Loss: 9.286150180364343e-05
INFO logger 2024-02-01 15:00:23,461 | server.py:212 | [Global round 19] Aggregating local models...
INFO logger 2024-02-01 15:00:23,463 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['LesCorts_2']
INFO logger 2024-02-01 15:00:23,525 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015304664239064076, mse: 0.019451484084129333, rmse: 0.13946857740770618, mae: 0.09933529049158096, nrmse: 1.8874911610985237
INFO logger 2024-02-01 15:00:23,644 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.0003411773419535653, mse: 0.04347097873687744, rmse: 0.20849695138509206, mae: 0.07863258570432663, nrmse: 1.1853492690840814
INFO logger 2024-02-01 15:00:23,685 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.2193677962672164e-05, mse: 0.0014671607641503215, rmse: 0.03830353461692956, mae: 0.02650074101984501, nrmse: 0.4808537692470427
INFO logger 2024-02-01 15:00:23,686 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['PobleSec_3', 'LesCorts_1', 'PobleSec_0', 'ElBorn_1', 'ElBorn_0', 'ElBorn_4', 'LesCorts_2', 'PobleSec_1', 'PobleSec_4', 'ElBorn_2', 'LesCorts_3', 'LesCorts_0', 'PobleSec_2', 'ElBorn_3', 'LesCorts_4']
INFO logger 2024-02-01 15:00:24,786 | train_utils.py:153 | Best Loss: 0.00034713287804803743
INFO logger 2024-02-01 15:00:25,443 | train_utils.py:153 | Best Loss: 8.40852168805309e-05
INFO logger 2024-02-01 15:00:26,440 | train_utils.py:153 | Best Loss: 0.00034276819366257726
INFO logger 2024-02-01 15:00:26,786 | train_utils.py:153 | Best Loss: 9.413529215560515e-06
INFO logger 2024-02-01 15:00:27,231 | train_utils.py:153 | Best Loss: 0.00015119997028639352
[31mStarting poisoning...!
INFO logger 2024-02-01 15:00:27,688 | train_utils.py:153 | Best Loss: 9.42497890147916e-06
INFO logger 2024-02-01 15:00:28,186 | train_utils.py:153 | Best Loss: 9.22763408692717e-05
INFO logger 2024-02-01 15:00:29,314 | train_utils.py:153 | Best Loss: 0.0003420630620433179
INFO logger 2024-02-01 15:00:30,462 | train_utils.py:153 | Best Loss: 0.00034879709593951705
INFO logger 2024-02-01 15:00:31,216 | train_utils.py:153 | Best Loss: 8.465514891187025e-06
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-01 15:00:31,878 | train_utils.py:153 | Best Loss: 0.00015502051267860054
INFO logger 2024-02-01 15:00:32,454 | train_utils.py:153 | Best Loss: 0.00016083082794184574
INFO logger 2024-02-01 15:00:33,259 | train_utils.py:153 | Best Loss: 0.0003485423720654423
[31mStarting poisoning...!
INFO logger 2024-02-01 15:00:33,759 | train_utils.py:153 | Best Loss: 0.00010640146143302537
INFO logger 2024-02-01 15:00:34,282 | train_utils.py:153 | Best Loss: 9.298993887962522e-05
INFO logger 2024-02-01 15:00:34,346 | server.py:212 | [Global round 20] Aggregating local models...
INFO logger 2024-02-01 15:00:34,347 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_3']
INFO logger 2024-02-01 15:00:34,465 | server.py:289 | [Dataset LesCorts Evaluation on 1368 samples] loss: 0.00015159331504473387, mse: 0.019267136231064796, rmse: 0.13880611020796166, mae: 0.0982866883277893, nrmse: 1.859843292820561
INFO logger 2024-02-01 15:00:34,598 | server.py:289 | [Dataset PobleSec Evaluation on 3175 samples] loss: 0.00034147060461576996, mse: 0.043508585542440414, rmse: 0.20858711739328586, mae: 0.07836021482944489, nrmse: 1.1865408062811829
INFO logger 2024-02-01 15:00:34,621 | server.py:289 | [Dataset ElBorn Evaluation on 828 samples] loss: 1.180489381082392e-05, mse: 0.0014206661144271493, rmse: 0.03769172474731223, mae: 0.02621551975607872, nrmse: 0.4880771597206133
INFO logger 2024-02-01 15:00:34,621 | server.py:133 | Time passed: 206.77846455574036 seconds.
INFO logger 2024-02-01 15:00:34,621 | server.py:134 | Best global model found on fl_round=0 with loss=0.0017594693884394996
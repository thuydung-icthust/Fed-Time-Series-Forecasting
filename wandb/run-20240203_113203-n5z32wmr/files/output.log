INFO logger 2024-02-03 11:32:07,137 | data_utils.py:383 | Observations info in ElBorn
INFO logger 2024-02-03 11:32:07,137 | data_utils.py:384 | 	Total number of samples:  4192
INFO logger 2024-02-03 11:32:07,137 | data_utils.py:385 | 	Number of samples for training: 3354
INFO logger 2024-02-03 11:32:07,137 | data_utils.py:386 | 	Number of samples for validation:  838
INFO logger 2024-02-03 11:32:07,139 | data_utils.py:383 | Observations info in LesCorts
INFO logger 2024-02-03 11:32:07,139 | data_utils.py:384 | 	Total number of samples:  6892
INFO logger 2024-02-03 11:32:07,139 | data_utils.py:385 | 	Number of samples for training: 5514
INFO logger 2024-02-03 11:32:07,139 | data_utils.py:386 | 	Number of samples for validation:  1378
INFO logger 2024-02-03 11:32:07,141 | data_utils.py:383 | Observations info in PobleSec
INFO logger 2024-02-03 11:32:07,141 | data_utils.py:384 | 	Total number of samples:  15927
INFO logger 2024-02-03 11:32:07,141 | data_utils.py:385 | 	Number of samples for training: 12742
INFO logger 2024-02-03 11:32:07,141 | data_utils.py:386 | 	Number of samples for validation:  3185
INFO logger 2024-02-03 11:32:07,143 | data_utils.py:389 | Observations info using all data
INFO logger 2024-02-03 11:32:07,143 | data_utils.py:390 | 	Total number of samples:  27011
INFO logger 2024-02-03 11:32:07,143 | data_utils.py:391 | 	Number of samples for training: 21610
INFO logger 2024-02-03 11:32:07,143 | data_utils.py:392 | 	Number of samples for validation:  5401
INFO logger 2024-02-03 11:32:07,143 | data_utils.py:118 | Using Flooring and Capping and with params: {'ElBorn': (10, 90), 'LesCorts': (10, 90), 'PobleSec': (5, 95)}
INFO logger 2024-02-03 11:32:07,809 | server.py:74 | Initializing client manager...
INFO logger 2024-02-03 11:32:07,809 | server.py:81 | Registering clients...
INFO logger 2024-02-03 11:32:07,809 | client_manager.py:66 | Registered client with id: ElBorn_0
INFO logger 2024-02-03 11:32:07,809 | client_manager.py:66 | Registered client with id: ElBorn_1
INFO logger 2024-02-03 11:32:07,809 | client_manager.py:66 | Registered client with id: ElBorn_2
INFO logger 2024-02-03 11:32:07,809 | client_manager.py:66 | Registered client with id: ElBorn_3
INFO logger 2024-02-03 11:32:07,809 | client_manager.py:66 | Registered client with id: ElBorn_4
INFO logger 2024-02-03 11:32:07,809 | client_manager.py:66 | Registered client with id: LesCorts_0
INFO logger 2024-02-03 11:32:07,809 | client_manager.py:66 | Registered client with id: LesCorts_1
INFO logger 2024-02-03 11:32:07,809 | client_manager.py:66 | Registered client with id: LesCorts_2
INFO logger 2024-02-03 11:32:07,809 | client_manager.py:66 | Registered client with id: LesCorts_3
INFO logger 2024-02-03 11:32:07,809 | client_manager.py:66 | Registered client with id: LesCorts_4
INFO logger 2024-02-03 11:32:07,810 | client_manager.py:66 | Registered client with id: PobleSec_0
INFO logger 2024-02-03 11:32:07,810 | client_manager.py:66 | Registered client with id: PobleSec_1
INFO logger 2024-02-03 11:32:07,810 | client_manager.py:66 | Registered client with id: PobleSec_2
INFO logger 2024-02-03 11:32:07,810 | client_manager.py:66 | Registered client with id: PobleSec_3
INFO logger 2024-02-03 11:32:07,810 | client_manager.py:66 | Registered client with id: PobleSec_4
INFO logger 2024-02-03 11:32:07,810 | server.py:85 | Client manager initialized!
INFO logger 2024-02-03 11:32:07,810 | server.py:67 | Aggregation algorithm: FedAvg()
INFO logger 2024-02-03 11:32:07,810 | client_manager.py:88 | Parameter c=0.0. Sampled 1 client(s): ['PobleSec_3']
X_val_sub.shape is 535 	 y_val_sub is 535
Clients participating training are: dict_keys(['ElBorn', 'LesCorts', 'PobleSec'])
INFO logger 2024-02-03 11:32:09,017 | server.py:99 | Starting FL rounds
INFO logger 2024-02-03 11:32:09,018 | client_manager.py:88 | Parameter c=1.0. Sampled 15 client(s): ['LesCorts_1', 'PobleSec_2', 'PobleSec_4', 'ElBorn_0', 'ElBorn_4', 'LesCorts_3', 'LesCorts_2', 'PobleSec_3', 'LesCorts_4', 'ElBorn_2', 'ElBorn_3', 'LesCorts_0', 'PobleSec_0', 'PobleSec_1', 'ElBorn_1']
INFO logger 2024-02-03 11:32:09,794 | train_utils.py:153 | Best Loss: 0.0002896100798708915
INFO logger 2024-02-03 11:32:10,344 | train_utils.py:153 | Best Loss: 0.00048219764949827213
[31mStarting poisoning...!
INFO logger 2024-02-03 11:32:11,072 | train_utils.py:153 | Best Loss: 0.0004605070486166111
INFO logger 2024-02-03 11:32:11,368 | train_utils.py:153 | Best Loss: 0.0002248865115829712
INFO logger 2024-02-03 11:32:11,557 | train_utils.py:153 | Best Loss: 2.704441241170887e-05
INFO logger 2024-02-03 11:32:11,886 | train_utils.py:153 | Best Loss: 0.0005417556082557516
INFO logger 2024-02-03 11:32:12,148 | train_utils.py:153 | Best Loss: 0.00021486838037769
INFO logger 2024-02-03 11:32:12,670 | train_utils.py:153 | Best Loss: 0.00046282758760288006
[31mStarting poisoning...!
INFO logger 2024-02-03 11:32:13,074 | train_utils.py:153 | Best Loss: 0.00017418319152461158
INFO logger 2024-02-03 11:32:13,301 | train_utils.py:153 | Best Loss: 2.86163878345925e-05
INFO logger 2024-02-03 11:32:13,510 | train_utils.py:153 | Best Loss: 0.0001446908842637271
INFO logger 2024-02-03 11:32:13,806 | train_utils.py:153 | Best Loss: 0.0007182669863976234
INFO logger 2024-02-03 11:32:14,431 | train_utils.py:153 | Best Loss: 0.000442783231663657
[31mStarting poisoning...!
[31mStarting poisoning...!
INFO logger 2024-02-03 11:32:15,189 | train_utils.py:153 | Best Loss: 0.0004338021676136753
INFO logger 2024-02-03 11:32:15,462 | train_utils.py:153 | Best Loss: 2.6967046345957523e-05
INFO logger 2024-02-03 11:32:15,702 | server.py:246 | [Global round 1] Aggregating local models...
Traceback (most recent call last):
  File "/home/judy/code/Fed-Time-Series-Forecasting/main.py", line 131, in <module>
    main(args)
  File "/home/judy/code/Fed-Time-Series-Forecasting/main.py", line 54, in main
    global_model, history = fit(
                            ^^^^
  File "/home/judy/code/Fed-Time-Series-Forecasting/fl_trainer.py", line 137, in fit
    model_params, history = server.fit(args.fl_rounds, args.fraction, use_carbontracker=use_carbontracker,
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/judy/code/Fed-Time-Series-Forecasting/ml/fl/server/server.py", line 114, in fit
    self.fit_round(fl_round=fl_round,
  File "/home/judy/code/Fed-Time-Series-Forecasting/ml/fl/server/server.py", line 189, in fit_round
    self.global_model = self.aggregate_models(fl_round, results, verifier_w)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/judy/code/Fed-Time-Series-Forecasting/ml/fl/server/server.py", line 247, in aggregate_models
    if not w:
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
Preds shape is: (15, 535, 5)
Preds shape by feat is: (15, 535)
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
end_idx: 20
end_idx: 40
end_idx: 60
end_idx: 80
end_idx: 100
end_idx: 120
end_idx: 140
end_idx: 160
end_idx: 180
end_idx: 200
end_idx: 220
end_idx: 240
end_idx: 260
end_idx: 280
end_idx: 300
end_idx: 320
end_idx: 340
end_idx: 360
end_idx: 380
end_idx: 400
end_idx: 420
end_idx: 440
end_idx: 460
end_idx: 480
end_idx: 500
end_idx: 520
end_idx: 535
[[208.]
 [478.]
 [495.]
 [431.]
 [378.]
 [483.]
 [165.]
 [493.]
 [232.]
 [345.]
 [400.]
 [437.]
 [474.]
 [479.]
 [333.]]